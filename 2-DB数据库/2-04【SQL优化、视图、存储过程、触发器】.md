# 第七章 MySQL锁机制

<!-- 共享读锁、排他写锁 -->

锁是计算机用以协调多个进程间并发访问同一共享资源的一种机制。MySQL中为了保证数据访问的一致性与有效性等功能，实现了锁机制，MySQL中的锁是在服务器层或者存储引擎层实现的。

锁是用来解决并发事务的访问问题，我们已经知道事务并发执行时可能带来的各种问题，最大的一个难点是：一方面要最大程度地利用数据库的并发访问，另外一方面还要确保每个用户能以一致的方式读取和修改数据，尤其是一个事务进行读取操作，另一个同时进行改动操作的情况下。

一个事务进行读取操作，另一个进行改动操作，这种情况下可能发生脏读、不可重复读、幻读的问题。有两种可选的解决方案：

* 方案一：读操作MVCC，写操作进行加锁。该方案性能较好，但可能会读到旧版本记录
* 方案二：读写操作都加锁。该方案性能一般，但是每次都可以读取到最新的记录，比如在银行场景中，对安全性要求非常高。

MySQL中的锁，可以根据模式、粒度、属性、状态、算法来进行分类：

* 模式分类：乐观锁、悲观锁。
* 粒度分类：全局锁、表级锁、行级锁。
* 属性分类：共享锁（又称为读锁，简称为S锁）、排他锁（又称为写锁和独占锁，简称为X锁）。
* 状态分类：意向共享锁、意向排他锁。
* 算法分类：间隙锁、临键锁、记录锁。

## 7.1 乐观锁和悲观锁

这两个锁并不存在，都是抽象的概念，需要我们自己去事项。乐观锁和悲观锁都是针对读（select）来说的。

**乐观锁**

乐观锁，就是非常乐观。乐观锁认为数据一般情况下不会造成冲突，在操作数据时不加锁，在进行更新后再去判断是否有冲突。乐观锁适用于读操作多，写操作少的场景。

乐观锁是基本版本号机制实现的，数据表中增加一个 version 字段，读取数据时将 version 一起读出。数据每更新一次，version 字段值 + 1。当修改需要提交时，将读取时的版本号与数据库当前版本号做比较，如果一致，说明在此期间无人修改这条记录，不一致则说明已经被修改了，提交失败。

**悲观锁**

悲观锁是相比较乐观锁而言的，就是比较悲观，悲观锁认为数据每次操作都会被修改，所以在每次操作数据时都会加上锁。

悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。MySQL中的悲观锁由共享锁或者排他锁实现，共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。

## 7.1 全局锁

全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DDL语句（建表、修改表结构等）、DML语句（数据的增删改）和已经更新操作的事务提交语句都将被阻塞。

其典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性。

```sql
-- 加上全局读锁，让整个库处于只读状态。这种方式叫做FTWRL（flush tables with read lock）
flush tables with read lock;
-- 数据备份，在shell窗口就可以 linxuan是数据库名称
mysqldump -u root –p 1234 linxuan > D:/linxuan.sql
-- 释放锁
unlock tables;
```

数据库中加全局锁，是一个比较重的操作，存在以下问题：

- 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。 
- 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。

可以通过只开启一个事务拿到一致性视图。在InnoDB引擎中，在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。我们可以在备份时加上参数 `--single-transaction` （开启单个事务）参数来完成不加锁的一致性数据备份。

除了FTWRL可以让整个库处于只读状态，还有一种方式`set global readonly = true`，但是这种方式并不推荐：

1. 在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，不建议使用。

2. 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。

## 7.2 表级锁

表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。

对于表级锁，主要分为以下四类： 表锁、元数据锁（meta data lock，MDL） 、意向锁、AUTO-INC 锁。

### 7.2.1 表锁

对于表锁，分为两类： 表共享读锁、表排他写锁。

```sql
-- 语法如下
-- 加锁，表共享锁或者表独占锁 lock tables student read;
lock tables 表名... read/write;
-- 释放锁，会释放当前会话的所有表锁。如果不释放当前锁，关闭本次会话连接也会释放锁。
unlock tables;
```

读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写。

- 表共享锁： 读锁不会阻塞其他客户端的读，但是会阻塞本客户端以及其他客户端的写。
- 表排他锁：写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写。


尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能。

### 7.2.2 元数据锁

元数据锁（meta data lock，MDL）：MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做变更。MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。

- 对一张表进行 CRUD 操作时，加的是 MDL 共享读锁；读锁和读锁不会冲突。
- 对一张表做结构变更操作的时候，加的是 MDL 排他写锁；读锁和写锁会冲突。

当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。

当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。

```sql
-- 使用performance_schema数据库。它提供底层监控功能，主要用于收集数据库服务器性能参数。
mysql> use performance_schema;
Database changed

-- 查看这个performance_schema数据库中metadata_locks表信息，也就是查看MDL信息。
mysql> select object_type, object_schema, object_name, lock_type, lock_duration from performance_schema.metadata_locks;
+-------------+--------------------+----------------+-------------+---------------+
| object_type | object_schema      | object_name    | lock_type   | lock_duration |
+-------------+--------------------+----------------+-------------+---------------+
| TABLE       | performance_schema | metadata_locks | SHARED_READ | TRANSACTION   |
+-------------+--------------------+----------------+-------------+---------------+
1 row in set (0.00 sec)
```

MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：

- 线程 A 启用了事务（但是一直不提交），然后执行一条 select 语句，此时先对该表加上 MDL 读锁；
- 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；
- 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞。

那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。

线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞。这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。

### 7.2.3 意向锁

意向锁的目的是为了快速判断表里是否有记录被加锁。为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。

假如没有意向锁，客户端一开启一个事务，然后执行DML操作，在执行DML语句时，会对涉及到的行加行锁。当客户端二想对这张表加表锁时，会检查当前表是否有对应的行锁，如果没有，则添加表锁，此时就会从第一行数据，检查到最后一行数据，效率较低。

![](D:/Java/笔记/图片/2-01【MySQL】/17-3.png)

有了意向锁之后，客户端一在执行DML操作时，会对涉及的行加行锁，同时也会对该表加上意向锁。而其他客户端，在对这张表加表锁的时候，会根据该表上所加的意向锁来判定是否可以成功加表锁，而不用逐行判断行锁情况了。

- 意向共享锁（Intention Share，简称IS）：在使用 InnoDB 引擎的表里对某些数据加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 意向排他锁（Intention Exclusive 简称IX）：在使用 InnoDB 引擎的表里对某些数据加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；也就是当执行插入、更新、删除操作，需要先对表加上「意向排他锁」，然后对该记录加排他锁。

意向共享锁和意向排他锁是表级锁，不会和行级的共享锁和排他锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和排他表锁（lock tables ... write）发生冲突。读读共享、读写互斥、写写互斥

一旦事务提交了，意向共享锁、意向排他锁，都会自动释放。

```sql
-- 查看意向锁及行锁的加锁情况
mysql> select object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;
Empty set (0.01 sec)
```

首先开启两个客户端。

```sql
-- 客户端1打开事务，并添加意向共享锁
mysql>  begin;
-- 添加了一个行级共享锁，在此之前会添加表级意向共享锁。
mysql>  select * from student where id  = 1 lock in share mode;
+----+--------+------------+
| id | name   | no         |
+----+--------+------------+
|  1 | 黛绮丝 | 2000100102 |
+----+--------+------------+
1 row in set (0.00 sec)
```

这个时候就能够在客户端2查看意向共享锁的情况了：

```sql
-- 客户端2
mysql>  select object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;
+-------------+------------+-----------+---------------+-----------+ -- lock_type：锁的类型
| object_name | index_name | lock_type | lock_mode     | lock_data | -- lock_mode：锁的方式
+-------------+------------+-----------+---------------+-----------+ -- TABLE：表锁
| student     | NULL       | TABLE     | IS            | NULL      | -- IS：意向共享锁
| student     | PRIMARY    | RECORD    | S,REC_NOT_GAP | 1         | -- RECORD：行锁
+-------------+------------+-----------+---------------+-----------+ -- S：共享锁
2 rows in set (0.00 sec)                                             -- REC_NOT_GAP：行锁
```

而这个时候在客户端2为表加共享读锁是没有任何问题的，但是加上表排他写锁就有问题了，就会被阻塞。

```sql
-- 添加一个表共享读锁，表共享读锁与表排他写锁冲突，与意向共享锁没有任何问题。
mysql> lock tables student read;
Query OK, 0 rows affected (0.00 sec)

-- 添加表排他写锁，与意向共享锁冲突，发生阻塞状态。
mysql> lock tables student write;
```

### 7.2.4 AUTO-INC/轻量级锁

在为某个字段声明 `AUTO_INCREMENT` 属性时，之后可以在插入数据时，可以不指定该字段的值，数据库会自动给该字段赋值递增的值，这主要是通过 AUTO-INC 锁实现的。

AUTO-INC 锁是特殊的表锁机制，它不是在一个事务提交后才释放，而是在执行完插入语句后就会立即释放。在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为 `AUTO_INCREMENT` 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。

一个事务在持有 AUTO-INC 锁的过程中，其他事务如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 `AUTO_INCREMENT` 修饰的字段的值是连续递增的。但是， 这样的话会导致AUTO-INC 锁在对大量数据进行插入的时候，会影响插入性能。

因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种轻量级的锁来实现自增。一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上`轻量级锁`，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。

InnoDB 存储引擎提供了个 `innodb_autoinc_lock_mode` 的系统变量，用来控制选择哪一种锁。

```sql
mysql> select @@innodb_autoinc_lock_mode;
+----------------------------+
| @@innodb_autoinc_lock_mode | -- 值为0，采用 AUTO-INC 锁
+----------------------------+ -- 值为2，采用轻量级锁
|                          2 | -- 值为1，两种锁混着用，能够确定插入数据的数量就采用轻量级锁，
+----------------------------+ --                    不确定时就采用 AUTO-INC 锁。 
1 row in set (0.00 sec)
```

当 `innodb_autoinc_lock_mode = 2` 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，这在有主从复制的场景中是不安全的。

## 7.4 行级锁

行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在InnoDB存储引擎中。

InnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。对于行级锁，主要分为以下三类：

* 行锁（Record Lock）：锁定单个行记录的锁，防止其他事务对此行进行update和delete。在RC(`read committed`)、RR(`repeatable read`)隔离级别下都支持。

  

* 间隙锁（Gap Lock）：锁定索引记录间隙（不含该记录），确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR(`repeatable read`)隔离级别下都支持。

  

* 临键锁（Next-Key Lock）：行锁和间隙锁组合，同时锁住数据，并锁住数据前面的间隙Gap。在RR隔离级别下支持。

  

### 7.4.1 行锁

![](D:/Java/笔记/图片/2-01【MySQL】/18-1.png)

InnoDB实现了以下两种类型的行锁：

- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。
- 排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他锁。

两种行锁的兼容情况如下:

| 共享锁和共享锁 | 共享锁和排他锁 | 排他锁和排他锁 |
| -------------- | -------------- | -------------- |
| 兼容           | 冲突           | 冲突           |

常见的SQL语句，在执行时，所加的行锁如下：

| SQL                           | 行锁类型   | 说明                                     |
| ----------------------------- | ---------- | ---------------------------------------- |
| INSERT / UPDATE / DELETE      | 排他锁     | 自动加锁                                 |
| SELECT（正常）                | 不加任何锁 |                                          |
| SELECT ... LOCK IN SHARE MODE | 共享锁     | 需要手动在SELECT之后加LOCK IN SHARE MODE |
| SELECT ... FOR UPDATE         | 排他锁     | 需要手动在SELECT之后加FOR UPDATE         |

默认情况下，InnoDB 在RR(`repeatable read`)事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。

- 针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。
- InnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记 录加锁，此时 就会升级为表锁。

```sql
-- 查看意向锁及行锁的加锁情况
select object_schema, object_name, index_name, lock_type, lock_mode, lock_data from
performance_schema.data_locks;
```

### 7.4.2 间隙锁

![](D:/Java/笔记/图片/2-01【MySQL】/18-2.png)

默认情况下，InnoDB在 RR(`repeatable read`)事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。

- 索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 。 
- 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。
- 索引上的范围查询(唯一索引)--会访问到不满足条件的第一个值为止。

注意：间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。

### 7.4.3 临键锁

![](D:/Java/笔记/图片/2-01【MySQL】/18-3.png)

# 第四章 SQL优化

```sql
# 创建一个表tb_user，查看表中字段
CREATE TABLE tb_user(
    id INT PRIMARY KEY AUTO_INCREMENT,
    NAME VARCHAR(50) NOT NULL,
    phone VARCHAR(11) NOT NULL,
    email VARCHAR(100),
    profession VARCHAR(11),
    age TINYINT UNSIGNED,
    gender CHAR(1),
    STATUS CHAR(1),
    createtime DATETIME
);
# 创建联合索引
create index idx_user_pro_age_sta on tb_user(profession, age, status);
# 创建前缀索引
create index idx_user_email_5 on tb_user(email(5));
# 显示索引
show index from tb_user;
+---------+------------+----------------------+--------------+-------------+
| Table   | Non_unique | Key_name             | Seq_in_index | Column_name |
+---------+------------+----------------------+--------------+-------------+
| tb_user |          0 | PRIMARY              |            1 | id          |
| tb_user |          1 | idx_user_pro_age_sta |            1 | profession  |
| tb_user |          1 | idx_user_pro_age_sta |            2 | age         |
| tb_user |          1 | idx_user_pro_age_sta |            3 | status      |
| tb_user |          1 | idx_user_email_5     |            1 | email       |
+---------+------------+----------------------+--------------+-------------+
```

## 2.4 性能分析

MySQL中性能分析的方式有：

* 查看当前数据库中语句执行频次：判断数据库以增删改查中哪一项为主，从而进行优化
* 开启慢查询日志：SQL语句抄过来慢查询规定的事件，那么就会被记录下来信息，方便分析。
* 开启profile文件：可以查看SQL语句的各个阶段的耗时时间。
* 查看SQL语句执行详细信息：通过explain或者desc查看当前SQL语句执行的详细信息。

**查看执行频次**

MySQL 客户端连接成功后，通过 `show [session | global] status` 命令可以提供服务器状态信息。通过如下指令，可以查看当前数据库的INSERT、UPDATE、DELETE、SELECT的访问频次：

```sql
-- session 是查看当前会话 ;
-- global 是查询全局数据 ;
SHOW GLOBAL STATUS LIKE 'Com_______';		-- 一共有7个下划线，com_______也可以
```

通过上述指令，我们可以查看到当前数据库到底是以查询为主，还是以增删改为主，从而为数据 库优化提供参考依据。 如果是以增删改为主，我们可以考虑不对其进行索引的优化。 如果是以查询为主，那么就要考虑对数据库的索引进行优化了。

**慢查询日志**

慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有SQL语句的日志。MySQL的慢查询日志默认没有开启，需要在MySQL的配置文件`/etc/my.cnf`中配置如下信息：

```sh
# 开启慢查询日志开关
slow_query_log=1
# 设置慢查询日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志
long_query_time=2
```

更改后重启MySQL服务。查看慢日志文件中记录的信息`/var/lib/mysql/localhost-slow.log`，查看慢查询日志开关状态`show variables like 'slow_query_log';`

**profile文件**

`show profiles` 能在做SQL优化时帮我们了解时间都耗费在哪里。通过 `have_profiling` 参数，能看到当前 MySQL 是否支持 profile 操作：

```sql
-- 查看当前MySQL是否支持 profile 操作，结果为YES那么代表支持，但是支持不一定代表开启这个功能，需要我们开启
SELECT @@have_profiling;
```

8.5版本的MySQL是支持 profile操作的，但是开关是关闭的。可以通过set语句在 session/global 级别开启profiling：

```sql
-- 开启profiling功能，这样可以查看语句的耗时。
SET profiling = 1;
-- 查看包含pro字符串的变量名，当然有profiling。这样就能看到它的开关是关闭的，也就是OFF。
show variables like "%pro%";
```

```sql
show profiles;							  -- 查看所有语句的耗时
show profile for query query_id;		    -- 查看指定query_id的SQL语句各个阶段的耗时 
show profile cpu for query query_id;	    -- 查看指定query_id的SQL语句CPU的使用情况
```

**explain**

<!-- explain 解释，说明，阐明 -->

EXPLAIN或者DESC命令获取执行SELECT语句的信息，包括SELECT语句执行过程中表如何连接和连接的顺序。

```sql
-- 直接在select语句之前加上关键字 explain / desc
EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件 ;
```

![](D:/Java/笔记/图片/2-01【MySQL】/12-8.png)

Explain 执行计划中各个字段的含义：

- `id`：select 查询的序列号，表示查询中执行 select 子句或者操作表的顺序（id相同，执行顺序从上到下；id不同，值越大越先执行）
- `select_type`：表示 SELECT 的类型，常见取值有 SIMPLE（简单表，即不适用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE之后包含子查询）等
- `type`：表示连接类型，性能由好到差的连接类型为 NULL、system、const、eq_ref、ref、range、index、all，尽量将性能提升到const就可以了。
- `possible_key`：可能应用在这张表上的索引，一个或多个
- `Key`：实际使用的索引，如果为 NULL，则没有使用索引
- `Key_len`：表示索引中使用的字节数，该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好
- `rows`：MySQL认为必须要执行的行数，在InnoDB引擎的表中，是一个估计值，可能并不总是准确的
- `filtered`：表示返回结果的行数占需读取行数的百分比，filtered的值越大越好。

## 4.1 新增优化

```sql
insert into tb_test values(1,'tom');
insert into tb_test values(2,'cat');
insert into tb_test values(3,'jerry');
.....
```

如果我们需要一次性往数据库表中插入多条记录，可以从以下三个方面进行优化。

1. 批量插入数据

   ```sql
   -- 这种方式建议插入1000条数据之内，如果超过了可以使用多条insert语句
   Insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry');
   ```

2. 手动控制事务

   ```sql
   start transaction;
   insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry');
   insert into tb_test values(4,'Tom'),(5,'Cat'),(6,'Jerry');
   insert into tb_test values(7,'Tom'),(8,'Cat'),(9,'Jerry');
   commit;
   ```

3. 主键顺序插入，性能要高于乱序插入。

   ```sql
   主键乱序插入 : 8 1 9 21 88 2 4 15 89 5 7 3
   主键顺序插入 : 1 2 3 4 5 7 8 9 15 21 88 89
   ```

如果一次性需要插入大批量数据（比如几百万的记录），使用insert语句插入性能较低，此时可以使用MySQL数据库提供的load指令进行插入（主键顺序插入性能高于乱序插入）。操作如下：

```sql
-- 客户端连接服务端时，加上参数 -–local-infile
mysql –-local-infile -u root -p

-- 查看从本地加载文件导入数据的开关是否打开，0为关闭，1为打开
select @@local_infile;

-- 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关
set global local_infile = 1;

-- 执行load指令将准备好的数据，加载到tb_user表结构中
-- 第一个‘,’的意思是每行数据每个字段之间的分隔符，‘\n’的意思是每行数据的分隔符
load data local infile '/usr/local/mysql/sql/load_user_100w_sort.sql' into table tb_user fields terminated by ',' lines terminated by '\n' ;
```

```sh
wc -l load_user_100w_sort.sql 		# 查看该文件有多少行
head load_user_100w_sort.sql 		# 查看该文件前十行
```

## 4.2 主键优化

主键设计原则：

* 满足业务需求的情况下，尽量降低主键的长度。 

  在InnoDB引擎中，索引分为聚集索引和二级索引。聚集索引只有一个，而二级索引有多个，二级索引的叶子节点中存储的就是主键。如果主键长度比较长，加上二级索引比较多，那么会占用大量的磁盘空间。搜索的时候也会耗费大量的磁盘IO。

* 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键。

* 尽量不要使用UUID做主键或者是其他自然主键，如身份证号。 

* 业务操作时，避免对主键的修改。

主键顺序插入的性能是要高于乱序插入的。 下面介绍一下具体的原因。在InnoDB存储引擎中，表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表IOT (index organized table IOT)。

![](D:\Java\笔记\图片\2-01【MySQL】\12-5.png)

行数据，都是存储在聚集索引的叶子节点上的。而我们之前也讲解过InnoDB的逻辑结构图：

![](D:\Java\笔记\图片\2-01【MySQL】\11.png)

在InnoDB引擎中，数据行是记录在逻辑结构 page 页中的，而每一个页的大小是固定的，默认16K。那也就意味着， 一个页中所存储的行也是有限的，如果插入的数据行row在该页存储比较大，那么将会存储到下一个页中，页与页之间会通过指针连接。

**页分裂**

页可以为空，也可以填充一半，也可以填充100%。每个页包含了2~N行数据(如果一行数据过大，会行溢出)，根据主键排列。

如果是主键顺序插入，那么不会有任何问题。从磁盘中申请页，主键顺序插入，当第一页写满之后，再写入第二个页，页与页之间会通过指针连接，之后再写入第三页。

![](D:\Java\笔记\图片\2-01【MySQL】\13.png)

但是主键乱序插入效果就不一样了。假如`1#`,`2#`页都已经写满了，存放了如图所示的数据

![](D:\Java\笔记\图片\2-01【MySQL】\13-1.png)

此时再插入id为50的记录，按照顺序，应该存储在47之后。但是47所在的1#页，已经写满了，存储不了50对应的数据了。 那么此时会开辟一个新的页 3#。

但是并不会直接将50存入3#页，而是会将1#页后一半的数据，移动到3#页，然后在3#页，插入50。

![](D:\Java\笔记\图片\2-01【MySQL】\13-2.png)

那么此时，这三个页之间的数据顺序是有问题的。 1#的下一个页应该是3#， 3#的下一个页是2#。 所以，此时需要重新设置链表指针。

![](D:\Java\笔记\图片\2-01【MySQL】\13-4.png)

上述的这种现象，称之为 "页分裂"，是比较耗费性能的操作。

**页合并**

目前表中已有数据的索引结构(叶子节点)如下：

![](D:\Java\笔记\图片\2-01【MySQL】\13-5.png)

当我们对已有数据进行删除时，实际上记录并没有被物理删除，只是记录被标记（flaged）为删除并且它的空间 变得允许被其他记录声明使用。

![](D:\Java\笔记\图片\2-01【MySQL】\13-6.png)

当页中删除的记录达到 `MERGE_THRESHOLD`（合并页的阈值，默认为页的50%），InnoDB会开始寻找最靠近的页（前 或后）看看是否可以将两个页合并以优化空间使用。

![](D:\Java\笔记\图片\2-01【MySQL】\13-7.png)

删除数据，并将页合并之后，再次插入新的数据21，则直接插入`3#`页。这个里面所发生的合并页的这个现象，就称之为 "页合并"。

## 4.3 order by优化

```sql
-- 查看索引
show index from tb_user;
+---------+----------------------+--------------+-------------+
| Table   | Key_name             | Seq_in_index | Column_name |
+---------+----------------------+--------------+-------------+
| tb_user | PRIMARY              |            1 | id          |
| tb_user | idx_user_pro_age_sta |            1 | profession  |
| tb_user | idx_user_pro_age_sta |            2 | age         |
| tb_user | idx_user_pro_age_sta |            3 | status      |
| tb_user | idx_user_email_5     |            1 | email       |
+---------+----------------------+--------------+-------------+
```

MySQL的排序，有两种方式：`Using filesort`和`Using index`。

- `Using filesort`：通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区sort buffer中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序。 
- `Using index`：通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高。优化排序操作时，尽量要优化为 Using index。

order by优化原则：

- 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则。
- 尽量使用覆盖索引。
- 多字段排序, 一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC/DESC）。 
- 如果不可避免的出现filesort，大数据量排序时，可以适当增大排序缓冲区大小 `sort_buffer_size`(默认256k)。

**根据排序字段建立合适的索引**

```sql
-- 查看id,age,phone字段，按照age升序排序
explain select id, age, phone from tb_user order by age ;
-- 查看id,age,phone字段，按照age, phone升序排序
-- 由于 age, phone 都没有索引，所以此时再排序时，出现Using filesort， 排序性能较低。
explain select id, age, phone from tb_user order by age, phone;

+----+-------------+---------+------+---------------+------+----------------+
| id | select_type | table   | type | possible_keys | key  | Extra          |
+----+-------------+---------+------+---------------+------+----------------+
|  1 | SIMPLE      | tb_user | ALL  | NULL          | NULL | Using filesort |	-- Using filesort
+----+-------------+---------+------+---------------+------+----------------+	-- 效率比较低
```

那么我们尝试为他们添加索引，然后再排序：

```sql
create index idx_user_age_phone_aa on tb_user(age, phone);	-- 创建索引 顺序是age,phone
explain select id,age,phone from tb_user order by age;		-- 排序
explain select id,age,phone from tb_user order by age , phone;	-- 排序

+-------------+
| Extra       |		-- 建立索引之后，再次进行排序查询，就由原来的Using filesort，变为了 Using index
+-------------+		-- 性能就是比较高的了。
| Using index |
+-------------+
```

之前创建的索引都是为他们进行升序排序，如果查询之后再降序排序会发生什么呢？

```sql
explain select id, age, phone from tb_user order by age desc, phone desc ;
```

答案就是也出现 `Using index`， 但是此时Extra中会出现 `Backward index scan`，这个代表反向扫描索引，因为在MySQL中我们创建的索引，默认索引的叶子节点是从小到大排序的，而此时我们查询排序时，是从大到小。所以，在扫描时，就是反向扫描，就会出现 `Backward index scan`。 

**多字段排序时，也遵循最左前缀法则**

```sql
-- 根据phone，age进行升序排序，phone在前，age在后。
explain select id, age, phone from tb_user order by phone, age;

-- 结果就是Using filesort
```

排序时，也需要满足最左前缀法则，否则也会出现 `filesort`。因为在创建索引的时候， age是第一个字段，phone是第二个字段，所以排序时，也就该按照这个顺序来，否则就会出现 `Using filesort`。

**多字段升序和降序，要注意索引创建时的规则**

```sql
-- age, phone进行降序一个升序，一个降序
explain select id, age, phone from tb_user order by age asc, phone desc ;

-- 因为创建索引时，如果未指定顺序，默认都是按照升序排序的，而查询时，一个升序，一个降序，此时就会出现Using filesort。
```

为了解决上述的问题，我们可以创建一个索引，这个联合索引中 age 升序排序，phone 倒序排序。`create index idx_user_age_phone_ad on tb_user(age asc, phone desc);`。这样结果就是Using index了。

## 4.4 group by优化

分组操作，我们主要来看看索引对于分组操作的影响。首先将tb_user表内索引除了主键索引外全部删除。

```sql
-- 删除索引
drop index idx_user_pro_age_sta on tb_user;
drop index idx_user_email_5 on tb_user;
```

接下来，在没有索引的情况下，执行如下SQL，查询执行计划：

```sql
explain select profession, count(*) from tb_user group by profession;
+----+------+-----------------+
| id | type | Extra           | -- type: ALL 性能较差   
+----+------+-----------------+ -- Extra: Using temporary 使用到了中间表
|  1 | ALL  | Using temporary |
+----+------+-----------------+
```

再针对于 profession， age，status 创建一个联合索引，再执行刚刚的SQL：

```sql
-- 创建索引
create index idx_user_pro_age_sta on tb_user(profession, age, status);
-- 查看执行情况
explain select profession, count(*) from tb_user group by profession;  
+----+-------+-------------+
| id | type  | Extra       | -- type: index性能比刚刚提升了  
+----+-------+-------------+ -- Extra: Using index  使用到了索引
|  1 | index | Using index |
+----+-------+-------------+
```

如果仅仅根据age分组，就会出现 Using temporary ；而如果是根据 profession，age两个字段同时分组，则不会出现 Using temporary。原因是因为对于分组操作，在联合索引中，也是符合最左前缀法则的。

所以，在分组操作中，我们需要通过以下两点进行优化，以提升性能：

1. 在分组操作时，可以通过索引来提高效率。 
2. 分组操作时，索引的使用也是满足最左前缀法则的。

## 4.5 limit优化

在数据量比较大时，如果进行limit分页查询，越往后，分页查询效率越低。

因为，当在进行分页查询时，如果执行 `limit 2000000, 10` ，此时需要MySQL排序前2000010记录，仅仅返回 2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大 。

一般分页查询时，通过创建覆盖索引能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化。

```sql
-- select id from tb_sku order by id limit 2000000, 10 只查询出来主键，然后根据主键查询
explain select * from tb_sku t, (select id from tb_sku order by id limit 2000000,10) a where t.id = a.id;
```

## 4.6 count优化

对于下面这条语句进行查询，如果数据少还没事，但是数据多了，那么便是灾难。

```sql
select count(*) from tb_user ;
```

这种情况在InnoDB中出现正常：

- MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 `count(*)` 的时候会直接返回这个数，效率很高； 但是如果是带条件的count，MyISAM也慢。 
- InnoDB 引擎就麻烦了，它执行 `count(*)` 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。

如果说要大幅度提升InnoDB表的count效率，可以自己计数（可以借助于redis这样的数据库进行，但是如果是带条件的count又比较麻烦了）。

`count()` 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是NULL，累计值就加 1，否则不加，最后返回累计值。 

用法：`count（主键）`、`count（字段）`、`count（数字）`、`count（*）`。

- `count（主键）`：InnoDB 引擎会遍历整张表，把每一行的主键id值都取出来，返回给服务层。服务层拿到主键后，直接按行进行累加(主键不可能为null)
- `count（字段）`：分为两种情况，有not null约束和没有not null约束。
  有not null 约束：InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，直接按行进行累加。
  没有not null 约束：InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为null，不为null，计数累加。 
- `count（数字）`：InnoDB 引擎遍历整张表，但不取值。服务层对于返回的每一行，放一个数字“1” 进去，直接按行进行累加。
- `count（*）`：InnoDB引擎并不会把全部字段取出来，而是专门做了优化不取值，服务层直接按行进行累加。

> 按照效率排序的话，`count(字段)` < `count(主键 id)` < `count(1)` ≈ `count(*)`，所以尽量使用 `count(*)`。

## 4.7 update优化

注意一下update语句执行时的注意事项：

```sql
-- 当我们在执行更新的SQL语句时，会锁定id为1这一行的数据，然后事务提交之后，行锁释放。
update course set name = 'javaEE' where id = 1 ;
```

但是当我们在执行如下SQL时：

```sql
-- 当我们开启多个事务，在执行上述的SQL时，我们发现行锁升级为了表锁。 导致该update语句的性能大大降低。
update course set name = 'SpringBoot' where name = 'PHP' ;
```

InnoDB的行锁是针对索引加的锁，不是针对记录加的锁 ,并且该索引不能失效，否则会从行锁升级为表锁 。

# 第五章 视图

视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。

通俗的讲，视图只保存了查询的SQL逻辑，不保存查询结果。所以我们在创建视图的时候，主要的工作就落在创建这条SQL查询语句上。

视图作用如下：

1. 简单。视图不仅可以简化用户对数据的理解，也可以简化他们的操作。那些被经常使用的查询可以被定义为视图，从而使得用户不必为以后的操作每次指定全部的条件。
2. 安全。数据库可以授权，但不能授权到数据库特定行和特定的列上。通过视图用户只能查询和修改他们所能见到的数据。
3. 数据独立。视图可帮助用户屏蔽真实表结构变化带来的影响。

基本语法如下：

```sql
-- 创建视图
CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [CASCADED | LOCAL ] CHECK OPTION ]
-- 例如创建一个视图stu_v_1
create or replace view stu_v_1 as select id, name from student where id <= 20 ;
```

```sql
-- 查询视图
SHOW CREATE VIEW 视图名称;
SELECT * FROM 视图名称 ...... ;
```

```sql
-- 修改视图
CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]
ALTER VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]
```

```sql
-- 删除视图
DROP VIEW [IF EXISTS] 视图名称 [,视图名称] ...
```

接下来，做一个测试，演示一下视图的插入和更新：

```sql
-- 创建视图
create or replace view stu_v_1 as select id, name from student where id <= 20 ;

select * from stu_v_1;
insert into stu_v_1 values(6, 'Tom');		-- 可以插入 也可以查出来
insert into stu_v_1 values(27, 'Tom22');		-- 可以插入 但是无法查出来
```

执行上述的SQL，我们会发现，id为6和27的数据都是可以成功插入的。 但是我们执行查询，查询出来的数据，却没有id为27的记录。因为我们在创建视图的时候，指定的条件为 `id<=20`，id为27的数据，是不符合条件的，所以没有查询出来，但是这条数据确实是已经成功的插入到了基表中。 

如果我们想要做到必须满足条件才能操作视图的话，那么就需要借助于视图的检查选项了。

## 5.1 检查选项

当使用`WITH CHECK OPTION`子句创建视图时，MySQL会通过视图检查正在更改的每个行，例如插入，更新，删除，以使其符合视图的定义。 

```sql
-- 创建视图的时候 有检查选项 只有满足id<=20才能够插入
create or replace view stu_v_1 as select id, name from stu where id <= 20 WITH CHECK OPTION ;
```

MySQL允许基于另一个视图创建视图，它还会检查依赖视图中的规则以保持一致性。为了确定检查的范围，mysql提供了两个选项： `CASCADED` 和 `LOCAL` ，默认值为 `CASCADED` 。

**CASCADED级联，向下检查**

![](..\图片\2-01【MySQL】\14.png)

接下来我们来尝试一下：

```sql
-- 创建视图stu_v_1
create or replace view stu_v_1 as select id, name from student where id <= 20 ;
insert into stu_v_1 values(6, 'Tom');		-- 可以插入 插入到了基表 也可以在视图查出来
insert into stu_v_1 values(27, 'Tom22');	-- 可以插入 插入到了基表 但是无法在视图查出来

-- 根据stu_v_1创建视图stu_v_2，添加上了cascaded检查选项，会向下检查。
create VIEW stu_v_2 AS  select id, name from stu_v_1 WHERE id >= 10 WITH CASCADED CHECK OPTION ;
INSERT INTO stu_v_2 VALUES (7, 'Tom');		-- 无法插入 不满足视图stu_v_2条件
INSERT INTO stu_v_2 VALUES (27, 'Tom');		-- 无法插入 不满足视图stu_v_1条件

-- 基于视图stu_v_2创建stu_v_3
create VIEW stu_v_3 AS select id, name from stu_v_2 WHERE id <= 15;
INSERT INTO stu_v_3 VALUES (12, 'Tom');		-- 可以插入，检查stu_v_2和stu_v_1成立，那么就插入
INSERT INTO stu_v_3 VALUES (18, 'Tom');		-- 可以插入，stu_v_3没有创建检查视图选项，所以不会检查，会检查stu_v_2和stu_v_1
```

**LOCAL本地**

比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为 local ，但是v1视图创建时未指定检查选项。 则在执行检查时，只会检查v2，不会检查v2的关联视图v1

![](..\图片\2-01【MySQL】\14-1.png)

```sql
-- 创建视图stu_v_4
create or REPLACE view stu_v_4 as SELECT id, name from stu where id <= 15;
insert into stu_v_4 VALUES (5, 'Tom');			-- 可以插入 插入到了基表 也可以在视图查出来
insert into stu_v_4 VALUES (16, 'Tom');			-- 可以插入 插入到了基表 但是无法在视图查出来

-- 基于视图stu_v_4创建视图stu_v_5
create view stu_v_5 as SELECT id, name from stu_v_4 where id >= 10 WITH LOCAL CHECK OPTION ;
INSERT INTO stu_v_5 VALUES (13, 'Tom'); 	-- 可以插入 满足当前视图检查 递归检查stu_v_4 发现没有检查选项
INSERT INTO stu_v_5 VALUES (17, 'Tom');		-- 可以插入 满足当前视图检查 递归检查stu_v_4 发现没有检查选项

-- 基于视图stu_v_5创建视图stu_v_6
create or replace VIEW stu_v_6 as select id, name from stu_v_5 where id < 20;
INSERT INTO stu_v_6 VALUES (14, 'Tom');		-- 可以插入
```

## 5.2 视图更新

要使视图可更新，那么视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下任何一项，则该视图不可更新：

- 聚合函数或窗口函数（SUM()、 MIN()、 MAX()、 COUNT()等） 
- DISTINCT 
- GROUP BY 
- HAVING 
- UNION 或者 UNION ALL

# 第六章 存储过程

存储过程是事先经过编译并存储在数据库中的一段 SQL 语句的集合，调用存储过程可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的。

存储过程思想上很简单，就是数据库 SQL 语言层面的代码封装与重用。

![](..\图片\2-01【MySQL】\15.png)

特点如下：

- 封装，复用。可以把某一业务SQL封装在存储过程中，需要用到的时候直接调用即可。 
- 可以接收参数，也可以返回数据。在存储过程中，可以传递参数，也可以接收返回值。 
- 减少网络交互，效率提升。如果涉及到多条SQL，每执行一次都是一次网络传输。 而如果封装在存储过程中，我们只需要网络交互一次可能就可以了。

基本语法如下：

```sql
CREATE PROCEDURE 存储过程名称 ([ 参数列表 ]) -- 创建存储过程
BEGIN
	SQL语句
END ;

create PROCEDURE p1()   -- 示例
BEGIN
    select * from student;
END;
```

```sql
CALL 名称 ([ 参数 ]);	-- 调用 格式
```

```sql
-- 查询指定数据库的存储过程及状态信息
SELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = '数据库名称'; 
-- 查询某个存储过程的定义
SHOW CREATE PROCEDURE 存储过程名称; 
```

```sql
-- 删除存储过程
DROP PROCEDURE [ IF EXISTS ] 存储过程名称;
```

因为存储过程中有着SQL语句，所以不可避免的存在`;`。如果在命令行中执行这个时候就会判定存储过程的SQL语句完毕，所以我们需要重新设置一下SQL语句的结束符。

```sql
-- 通过关键字delimiter指定SQL语句的结束符。这样就代表修改了结束符了，修改为了$$
-- 最后记得再修改回来 delimiter ;
delimiter $$
```

## 6.1 变量

在MySQL中变量分为三种类型: 系统变量、用户定义变量、局部变量。

**系统变量**

系统变量是MySQL服务器提供，不是用户定义的，属于服务器层面。分为全局变量（GLOBAL）、会话变量（SESSION）。

- 全局变量（GLOBAL）：全局变量针对于所有的会话。 
- 会话变量（SESSION）：会话变量针对于单个会话，在另外一个会话窗口就不生效了。

如果没有指定SESSION/GLOBAL，默认是SESSION，会话变量。

```sql
-- 查看所有系统变量
SHOW [ SESSION | GLOBAL ] VARIABLES ; 
-- 可以通过LIKE模糊匹配方式查找变量
SHOW [ SESSION | GLOBAL ] VARIABLES LIKE '......'; 
-- 查看指定变量的值
-- 一个@是用户定义变量，两个@是系统定义变量。
SELECT @@[SESSION | GLOBAL] 系统变量名; 
```

```sql
-- 设置系统变量
SET [ SESSION | GLOBAL ] 系统变量名 = 值 ;
-- 一个@是用户定义变量，两个@是系统定义变量。
SET @@[SESSION | GLOBAL]系统变量名 = 值 ;
```

mysql服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在 `/etc/my.cnf` 中配置。

**用户自定义变量**

用户自定义变量是用户根据需要自己定义的变量，用户变量不用提前声明，在用的时候直接用`@变量名`使用就可以。其作用域为当前连接。

```sql
-- 第一种赋值方式，使用set赋值。赋值的时候可以使用 = ，也可以使用 := ，推荐使用第二种赋值方式。
SET @var_name = expr [, @var_name = expr] ... ;
SET @var_name := expr [, @var_name := expr] ... ;

-- 第二种赋值方式
SELECT @var_name := expr [, @var_name := expr] ... ;
SELECT 字段名 INTO @var_name FROM 表名;

-- 使用
SELECT @var_name ; 
```

用户定义的变量无需对其进行声明或初始化，只不过获取到的值为NULL。

```sql
-- 赋值
set @myname = 'linxuan';
set @myage := 10;
set @mygender := '男', @myhobby := 'java';
select @mycolor := 'red';
select count(*) into @mycount from tb_user;

-- 使用
select @myname, @myage, @mygender, @myhobby;
select @mycolor, @mycount;
select @abc;
```

**局部变量**

局部变量是根据需要定义的在局部生效的变量，访问之前，需要`DECLARE`声明。可用作存储过程内的局部变量和输入参数，局部变量的范围是在其内声明的`BEGIN ... END`块。

```sql
-- 声明局部变量。变量类型就是数据库字段类型，例如INT、BIGINT、CHAR、VARCHAR、DATE、TIME等。
DECLARE 变量名 变量类型 [DEFAULT ... ] ;

-- 赋值
SET 变量名 = 值 ;
SET 变量名 := 值 ;
SELECT 字段名 INTO 变量名 FROM 表名 ... ;
```

```sql
-- 声明局部变量 - declare
-- 赋值
create procedure p2()
begin
	declare stu_count int default 0;
	select count(*) into stu_count from student;
	select stu_count;
end;

call p2();
```

## 6.2 if判断

if 用于做条件判断，具体的语法结构为：

```sql
IF 条件1 THEN
	.....
ELSEIF 条件2 THEN -- 可选
	.....
ELSE -- 可选
	.....
END IF;
```

在if条件判断的结构中，ELSE IF 结构可以有多个，也可以没有。 ELSE结构可以有，也可以没有。

```sql
create PROCEDURE p3()
BEGIN
    DECLARE score int DEFAULT 58;
    declare result VARCHAR(10);

    if score >= 85 then
        set result := '优秀';
    elseif score >= 60 then
        SET result := '及格';
    else
        SET result := '不及格';
    END IF;
    SELECT result;
END;

CALL p3();
```

## 6.3 参数

参数的类型，主要分为以下三种：IN、OUT、INOUT。 具体的含义如下：

- IN：该类参数作为输入，也就是需要调用时传入值，默认。 
- OUT：该类参数作为输出，也就是该参数可以作为返回值 
- INOUT：既可以作为输入参数，也可以作为输出参数

```sql
CREATE PROCEDURE 存储过程名称 ([ IN/OUT/INOUT 参数名 参数类型 ])
BEGIN
	-- SQL语句
END ;
```

```sql
create procedure p4(in score int, out result varchar(10))
begin
	if score >= 85 then
		set result := '优秀';
	elseif score >= 60 then
		set result := '及格';
	else
		set result := '不及格';
	end if;
end;

-- 定义用户变量 @result来接收返回的数据, 用户变量可以不用声明
call p4(18, @result);
select @result;
```

## 6.4 case

case和流程控制函数很类似。有两种语法格式：

```sql
-- 第一种格式，含义：当case_value的值为 when_value1时，执行statement_list1，当值为 when_value2时，执行statement_list2，否则就执行 statement_list
CASE case_value
	WHEN when_value1 THEN statement_list1
	[ WHEN when_value2 THEN statement_list2] ...
	[ ELSE statement_list ]
END CASE;

-- 第二种格式，含义：当条件search_condition1成立时，执行statement_list1，当条件search_condition2成立时，执行statement_list2，否则就执行 statement_list
CASE
	WHEN search_condition1 THEN statement_list1
	[WHEN search_condition2 THEN statement_list2] ...
	[ELSE statement_list]
END CASE;
```

## 6.5 循环

有多种循环方式：while循环、repeat循环、loop循环、

**While循环**

while 循环是有条件的循环控制语句。满足条件后，再执行循环体中的SQL语句。具体语法为：

```sql
-- 先判定条件，如果条件为true，则执行逻辑，否则，不执行逻辑
WHILE 条件 DO
	SQL逻辑...
END WHILE;
```

**repeat循环**

repeat是有条件的循环控制语句，当满足until声明的条件的时候，则退出循环 。具体语法为：

```sql
-- 先执行一次逻辑，然后判定UNTIL条件是否满足，如果满足，则退出。如果不满足，则继续下一次循环
REPEAT
	SQL逻辑...
	UNTIL 条件
END REPEAT;
```

**loop循环**

LOOP 实现简单的循环，如果不在SQL逻辑中增加退出循环的条件，可以用其来实现简单的死循环。LOOP可以配合一下两个语句使用： 

- `LEAVE` ：配合循环使用，退出循环。
- `ITERATE`：必须用在循环中使用，其他地方使用不了。作用是跳过当前循环剩下的语句，直接进入下一次循环。

```sql
[begin_label:] LOOP
SQL逻辑...
END LOOP [end_label];

-- 退出指定标记的循环体
LEAVE label;
-- 直接进入下一次循环
ITERATE label; 
```

上述语法中出现的 `begin_label`、`end_label`、`label` 指的都是我们所自定义的标记。

```sql
-- A. 定义局部变量, 记录累加之后的值;
-- B. 每循环一次, 就会对n进行-1 , 如果n减到0, 则退出循环 ----> leave xx
create procedure p9(in n int)
begin
	declare total int default 0;

	sum:loop
		if n <= 0 then
			leave sum;
		end if;
		
		set total := total + n;
		set n := n - 1;
	end loop sum;
	
	select total;
end;

call p9(100);
```

## 6.7 游标CURSOR

游标（CURSOR）是用来存储查询结果集的数据类型，在存储过程和函数中可以使用游标对结果集进行循环的处理。游标的使用包括游标的声明、OPEN、FETCH 和 CLOSE，其语法如下：

```sql
-- 声明游标
DECLARE 游标名称 CURSOR FOR 查询语句;
-- 打开游标
OPEN 游标名称;
-- 获取游标记录
FETCH 游标名称 INTO 变量 [, 变量 ];
-- 关闭游标
CLOSE 游标名称;
```

来看一个案例：根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名 （name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表 (id, name, profession)中。

```sql
-- 逻辑:
-- A. 声明游标, 存储查询结果集
-- B. 准备: 创建表结构
-- C. 开启游标
-- D. 获取游标中的记录
-- E. 插入数据到新表中
-- F. 关闭游标
create procedure p11(in uage int)
begin
	declare uname varchar(100);
	declare upro varchar(100);
	declare u_cursor cursor for select name, profession from tb_user where age <= uage;
	
	drop table if exists tb_user_pro;
	create table if not exists tb_user_pro(
		id int primary key auto_increment,
		name varchar(100),
		profession varchar(100)
	);
	
	open u_cursor;
	while true do
		fetch u_cursor into uname, upro;
		insert into tb_user_pro values (null, uname, upro);
	end while;
	
	close u_cursor;
end;

call p11(30);
```

上述的存储过程，最终我们在调用的过程中会报错。这是因为上面的while循环中，并没有退出条件。当游标的数据集获取完毕之后，再次获取数据，就会报错，从而终止了程序的执行。但是在报错之前，`tb_user_pro`表结构及其数据都已经插入成功了，我们可以直接刷新表结构，检查表结构中的数据。

上述的功能，虽然我们实现了，但是逻辑并不完善，而且程序执行完毕，获取不到数据，数据库还报错。 要想解决这个问题，就需要通过MySQL中提供的 条件处理程序 Handler 来解决。

## 6.8 条件处理Handler

条件处理程序（Handler）可以用来定义在流程控制结构执行过程中遇到问题时相应的处理步骤。具体语法为

```sql
DECLARE handler_action HANDLER FOR condition_value [, condition_value] ... statement ;

handler_action 的取值：
    CONTINUE: 继续执行当前程序
    EXIT: 终止执行当前程序

condition_value 的取值：
	SQLSTATE sqlstate_value: 状态码，如 02000
	
	SQLWARNING: 所有以01开头的SQLSTATE代码的简写
	NOT FOUND: 所有以02开头的SQLSTATE代码的简写
	SQLEXCEPTION: 所有没有被SQLWARNING 或 NOT FOUND捕获的SQLSTATE代码的简写
```

可以根据条件处理程序来完善上面的程序：

```sql
create procedure p11(in uage int)
begin
	declare uname varchar(100);
	declare upro varchar(100);
	declare u_cursor cursor for select name,profession from tb_user where age <= uage;
	-- 声明条件处理程序： 当SQL语句执行抛出的状态码为02000时，将关闭游标u_cursor，并退出
	declare exit handler for SQLSTATE '02000' close u_cursor;
	-- 也可以通过SQLSTATE的代码简写方式 NOT FOUND declare exit handler for not found close u_cursor;
	
	drop table if exists tb_user_pro;
	create table if not exists tb_user_pro(
		id int primary key auto_increment,
		name varchar(100),
		profession varchar(100)
	);
	
	open u_cursor;
	while true do
		fetch u_cursor into uname,upro;
		insert into tb_user_pro values (null, uname, upro);
	end while;
	
	close u_cursor;
end;

call p11(30);
```

## 6.9 存储函数

存储函数是有返回值的存储过程，存储函数的参数只能是IN类型的。具体语法如下：

```sql
CREATE FUNCTION 存储函数名称 ([ 参数列表 ])
RETURNS type [characteristic ...]
BEGIN
	-- SQL语句
	RETURN ...;
END ;
```

`characteristic`说明：

- `DETERMINISTIC`：相同的输入参数总是产生相同的结果
- `NO SQL` ：不包含 SQL 语句。
- `READS SQL DATA`：包含读取数据的语句，但不包含写入数据的语句。

案例：计算从1累加到n的值，n为传入的参数值。

```sql
create function fun1(n int)
returns int deterministic
begin
	declare total int default 0;

	while n > 0 do
		set total := total + n;
		set n := n - 1;
	end while;
	
	return total;
end;

select fun1(50);
```

在mysql8.0版本中binlog默认是开启的，一旦开启了，mysql就要求在定义存储过程时，需要指定 characteristic特性，否则就会错误。

# 第七章 触发器TRIGGER

触发器是与表有关的数据库对象，指在`insert/update/delete`之前或之后，触发并执行触发器中定义的SQL语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性，日志记录，数据校验等操作 。

使用别名OLD和NEW来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。

- `INSERT`型触发器：NEW 表示将要或者已经新增的数据 
- `UPDATE`型触发器：OLD 表示修改之前的数据，NEW 表示将要或已经修改后的数据 
- `DELETE`型触发器：OLD 表示将要或者已经删除的数据

```sql
-- 创建触发器
CREATE TRIGGER trigger_name
BEFORE/AFTER INSERT/UPDATE/DELETE
ON tbl_name FOR EACH ROW -- 行级触发器
BEGIN
	trigger_stmt ;
END;
```

```sql
-- 查看触发器
SHOW TRIGGERS ;
```

```sql
-- 删除触发器
-- 如果没有指定 schema_name，默认为当前数据库。
DROP TRIGGER [schema_name.]trigger_name ; 
```

