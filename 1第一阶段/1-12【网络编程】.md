# 第四章 OSI七层模型

应用--表示--会话--传输--网络--数据链路--物理

![](D:\Java\笔记\图片\1-11【网络编程】\OSI七层模型.png)



| OSI七层模型 | 功能                                                         | 对应的网络协议                                               |
| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 应用层      | 文件传输，文件管理，电子邮件的信息处理——apdu                 | HTTP、TFTP, FTP, NFS, WAIS、POP3、SMTP                       |
| 表示层      | 确保一个系统的应用层发送的消息可以被另一个系统的应用层读取，编码转换，数据解析，管理数据的解密和加密，最小单位——ppdu | Telnet, Rlogin, SNMP, Gopher                                 |
| 会话层      | 负责在网络中的两节点建立，维持和终止通信，在一层协议中，可以解决节点连接的协调和管理问题。包括通信连接的建立，保持会话过程通信连接的畅通，两节点之间的对话，决定通信是否被终端一斤通信终端是决定从何处重新发送，最小单位——spdu | SMTP, DNS                                                    |
| 传输层      | 定义一些传输数据的协议和端口。传输协议同时进行流量控制，或是根据接收方接收数据的快慢程度，规定适当的发送速率，解决传输效率及能力的问题——tpdu | TCP, UDP                                                     |
| 网络层      | 控制子网的运行，如逻辑编址，分组传输，路由选择最小单位——分组（包）报文 | IP, ICMP, ARP, RARP, AKP, UUCP                               |
| 数据链路层  | 主要是对物理层传输的比特流包装，检测保证数据传输的可靠性，将物理层接收的数据进行MAC（媒体访问控制）地址的封装和解封装，也可以简单的理解为物理寻址。交换机就处在这一层，最小的传输单位——帧 | FDDI, Ethernet, Arpanet, PDN, SLIP, PPP，STP。HDLC,SDLC,帧中继 |
| 物理层      | 定义物理设备的标准，主要对物理连接方式，电气特性，机械特性等制定统一标准，传输比特流，因此最小的传输单位——位（比特流） | IEEE 802.1A, IEEE 802.2到IEEE 802.                           |

应用--表示--会话--传输--网络--数据链路--物理

**应用层**

​    OSI参考模型中最靠近用户的一层，是为计算机用户提供应用接口，也为用户直接提供各种网络服务。我们常见应用层的网络服务协议有：HTTP，HTTPS，FTP，POP3、SMTP等。

​    实际公司A的老板就是我们所述的用户，而他要发送的商业报价单，就是应用层提供的一种网络服务，当然，老板也可以选择其他服务，比如说，发一份商业合同，发一份询价单，等等。

**表示层**

​    表示层提供各种用于应用层数据的编码和转换功能,确保一个系统的应用层发送的数据能被另一个系统的应用层识别。如果必要，该层可提供一种标准表示形式，用于将计算机内部的多种数据格式转换成通信中采用的标准表示形式。数据压缩和加密也是表示层可提供的转换功能之一。

​    由于公司A和公司B是不同国家的公司，他们之间的商定统一用英语作为交流的语言，所以此时表示层（公司的文秘），就是将应用层的传递信息转翻译成英语。同时为了防止别的公司看到，公司A的人也会对这份报价单做一些加密的处理。这就是表示的作用，将应用层的数据转换翻译等。

**会话层**

​    会话层就是负责建立、管理和终止表示层实体之间的通信会话。该层的通信由不同设备中的应用程序之间的服务请求和响应组成。   

​    会话层的同事拿到表示层的同事转换后资料，（会话层的同事类似公司的外联部），会话层的同事那里可能会掌握本公司与其他好多公司的联系方式，这里公司就是实际传递过程中的实体。他们要管理本公司与外界好多公司的联系会话。当接收到表示层的数据后，会话层将会建立并记录本次会话，他首先要找到公司B的地址信息，然后将整份资料放进信封，并写上地址和联系方式。准备将资料寄出。等到确定公司B接收到此份报价单后，此次会话就算结束了，外联部的同事就会终止此次会话。

**传输层**

​    传输层建立了主机端到端的链接，传输层的作用是为上层协议提供端到端的可靠和透明的数据传输服务，包括处理差错控制和流量控制等问题。该层向高层屏蔽了下层数据通信的细节，使高层用户看到的只是在两个传输实体间的一条主机到主机的、可由用户控制和设定的、可靠的数据通路。我们通常说的，TCP UDP就是在这一层。端口号既是这里的“端”。

​    传输层就相当于公司中的负责快递邮件收发的人，公司自己的投递员，他们负责将上一层的要寄出的资料投递到快递公司或邮局。

**网络层**

​    本层通过IP寻址来建立两个节点之间的连接，为源端的运输层送来的分组，选择合适的路由和交换节点，正确无误地按照地址传送给目的端的运输层。就是通常说的IP层。这一层就是我们经常说的IP协议层。IP协议是Internet的基础。

​    网络层就相当于快递公司庞大的快递网络，全国不同的集散中心，比如说，从深圳发往北京的顺丰快递（陆运为例啊，空运好像直接就飞到北京了），首先要到顺丰的深圳集散中心，从深圳集散中心再送到武汉集散中心，从武汉集散中心再寄到北京顺义集散中心。这个每个集散中心，就相当于网络中的一个IP节点。

**数据链路层** 

​    将比特组合成字节,再将字节组合成帧,使用链路层地址 (以太网使用MAC地址)来访问介质,并进行差错检测。

   数据链路层又分为2个子层：逻辑链路控制子层（LLC）和媒体访问控制子层（MAC）。

​    MAC子层处理CSMA/CD算法、数据出错校验、成帧等；LLC子层定义了一些字段使上次协议能共享数据链路层。 在实际使用中，LLC子层并非必需的。

**物理层**   

​    实际最终信号的传输是通过物理层实现的。通过物理介质传输比特流。规定了电平、速度和电缆针脚。常用设备有（各种物理设备）集线器、中继器、调制解调器、网线、双绞线、同轴电缆。这些都是物理层的传输介质。

​     快递寄送过程中的交通工具，就相当于我们的物理层，例如汽车，火车，飞机，船。

# 第五章 TCP/IP网络协议五层模型

自底向上分别为物理层、链接层、网络层、传输层、应用层。

应用--传输--网络--数据链路--物理

![](D:\Java\笔记\图片\1-11【网络编程】\五层模型.png)

## 5.1 物理层

两个网络设备间实现比特流的透明传输，传输010101二进制的电信号。

## 5.2 数据链路层

单纯的0和1没有意义，必须规定解读方式：多少个电信号为一组，每个信号应有何意义。这就是“链路层”的功能。

**数据链路层以太网协议**

以太网规定，一组电信号构成一个数据包，叫做帧，每一帧分成两个部分：标头（Head）和数据（Data）。

“标头”包含数据包的一些说明项，比如发送者、接受者、数据类型等等；“数据”则是数据包的具体内容。

“标头”的长度，固定为18字节。“数据”的长度，最短为46字节，最长为1500字节。因此，整个帧最短为64字节，最长为1518字节。如果数据很长，就必须分割成多个帧进行发送。

**MAC地址**

发送者和接受者如何标识呢？

以太网规定，进入网络所有设备，都必须具有“网卡”接口。数据包必须是从一块网卡。传送到另一块网卡。网卡的地址，就是数据包的发送地址和接收地址，这叫做MAC地址。

每块网卡出厂的时候，都有一个全世界独一无二的ＭＡＣ地址，长度是48个二进制位，通常用１２个十六进制数表示。

**广播**

定义地址只是第一步，后面还有更多步骤。

首先，一块网卡如何知道另一块网卡的ＭＡＣ地址？ARP协议可以解决这个问题。

有了ＭＡＣ地址，系统怎样才能把数据包准确送到接收方？

以太网采用了一种原始的方式，它不是把数据包准确送到接收方，而是向本网络内所有计算机发送，让每台计算机自己判断，是否为接收方。

![](D:\Java\笔记\图片\1-11【网络编程】\广播.png)

上图中，1号计算机向2号计算机发送一个数据包，同一个子网络的3号、4号、5号计算机都会收到这个包。它们读取这个包的"标头"，找到接收方的MAC地址，然后与自身的MAC地址相比较，如果两者相同，就接受这个包，做进一步处理，否则就丢弃这个包。这种发送方式就叫做"广播"（broadcasting）。

## 5.3 网络层

网络层的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络，这套地址就叫做“网络地址”，简称网址。

网址帮助我们确定计算机所在的子网络，MAC地址是绑定网卡上的，网络地址则是管理员分配的，它们只是随机组合在一起。

网址帮助我们确定计算机所在的子网络，mac地址则将数据包送到该子网络中的目标网卡。因此，从逻辑上可以推断，必定是先处理网络地址，然后再处理MAC地址。

**IP协议**

IP协议的作用主要有两个，一个是为每一台计算机分配IP地址，另一个是确定哪些地址在同一个子网络。

规定网络地址的协议，叫做IP协议。它所在的地址，被称为IP地址。目前广泛采用的是IP协议第四版，规定网络地址由32个二进制位组成。习惯上，我们用分成四段的十进制数表示IP地址，从0.0.0.0到255.255.255.255.每个字段是一个字节，8位，最大值是255.地址分为两个部分，前一部分代表网络，后一部分代表主机。

IP地址不能直接用来进行通信，在实际网络的链路上传送数据帧必须使用硬件地址。IP地址的四大类型标识的是网络中的某台主机。IPv4的地址长度为32位，共4个字节，

Ip地址根据网络号和主机号分为A,B,C三类及特殊地址D、E，全0和全1的都保留不用。大多数公司都使用A类网络地址的一大原因，因为它们可使用所有的子网掩码，进行网络设计时的灵活性最大。

互联网上的每一台计算机，都会分配到一个IP地址。这个地址分为两个部分，前一部分代表网络，后一部分代表主机。比如，IP地址172.16.254.1，这是一个32位的地址，假定它的网络部分是前24位（172.16.254），那么主机部分就是后8位（最后的那个1）。

![](D:\Java\笔记\图片\1-11【网络编程】\IP地址.png)

* A类：(1.0.0.0-126.0.0.0)（默认子网掩码：255.0.0.0或 0xFF000000）第一个字节为网络号，后三个字节为主机号。该类IP地址的最前面为“0”，即最大为01111111127，但是127被用作测试使用，所以最大为126，所以地址的网络号取值于1~126之间。一般用于大型网络。

* B类：(128.0.0.0-191.255.0.0)（默认子网掩码：255.255.0.0或0xFFFF0000）前两个字节为网络号，后两个字节为主机号。该类IP地址的最前面为“10”，1000 0000（128）-1011 1111（191）所以地址的网络号取值于128~191之间。一般用于中等规模网络。

* C类：(192.0.0.0-223.255.255.0)（子网掩码：255.255.255.0或 0xFFFFFF00）前三个字节为网络号，最后一个字节为主机号。该类IP地址的最前面为“110”，1100 0000（192）-1101 1111（223） 所以地址的网络号取值于192~223之间。一般用于小型网络。

* D类：是多播地址。该类IP地址的最前面为“1110”，所以地址的网络号取值于224~239之间。一般用于多路广播用户。

* E类：是保留地址。该类IP地址的最前面为“1111”，所以地址的网络号取值于240~255之间。

在IP地址3种主要类型里，各保留了3个区域作为私有地址，其地址范围如下：

* A类地址：10.0.0.0～10.255.255.255
* B类地址：172.16.0.0～172.31.255.255
* C类地址：192.168.0.0～192.168.255.255

回送地址：127.0.0.1。 也是本机地址，等效于localhost或本机IP。一般用于测试使用。例如：ping 127.0.0.1来测试本机TCP/IP是否正常。

互联网上的每一台计算机，都会分配到一个IP地址。这个地址分为两个部分，前一部分代表网络，后一部分代表主机。比如，IP地址172.16.254.1，这是一个32位的地址，假定它的网络部分是前24位（172.16.254），那么主机部分就是后8位（最后的那个1）。处于同一个子网络的电脑，它们IP地址的网络部分必定是相同的，也就是说172.16.254.2应该与172.16.254.1处在同一个子网络。

但是，问题在于单单从IP地址，我们无法判断网络部分，还是以172.16.254.1为例，它的网络部分，到底是前24位，还是前16位，甚至是前28位，从IP地址上是看不出来的。

判断两台计算机属于同一个子网络，需要用到“子网掩码”：

所谓“子网掩码”，就是表示子网络特征的一个参数。它在形式上等同于IP地址，也是一个32位二进制数字，它的网络部分全部为1，主机部分全部为0。比如，IP地址172.16.254.1，如果已知网络部分是前24位，主机部分是后8位，那么子网络掩码就是11111111.11111111.11111111.00000000，写成十进制就是255.255.255.0。

知道“子网掩码”，我们就能判断，任意两个IP地址是否处于同一个子网络，方法是将两个IP地址与子网掩码分别进行AND运算，结果相同则说明在同一个子网络中。

比如，已知IP地址172.16.254.1和172.16.254.233的子网掩码都是255.255.255.0，请问它们是否在同一个子网络？两者与子网掩码分别进行AND运算，结果都是172.16.254.0，因此它们在同一个子网络。

> 子网掩码：通过子网掩码和ip判断两个ip是否处于同一个网段,通过ip地址和子网掩码做按位与运算
>
> - 172.16.10.1：10101100.00010000.00001010.000000001
>   - 255.255.255.0:11111111.11111111.11111111.00000000
>   - AND运算得网络地址结果：10101100.00010000.00001010.000000000->172.16.10.0
>
> - 172.16.10.2：10101100.00010000.00001010.000000010
>
>   - 255.255.255.0:11111111.11111111.11111111.00000000
>
>   - AND运算得网络地址结果：10101100.00010000.00001010.000000000->172.16.10.0
>
>
> * 结果都是172.16.10.0，因此它们在同一个子网络。

IP协议的作用主要有两个，一个是为每一台计算机分配IP地址，另一个是确定哪些地址在同一个子网络。

**ARP协议**

APR协议：解决同一个局域网上的主机或路由器的IP地址和硬件地址的映射问题。ARP是在仅知道主机的IP地址时确定其物理地址的协议。

ARP协议：广播的方式发送数据包，获取目标主机的mac地址

**RARP协议**

RARP协议：解决同一个局域网上的主机或路由器的硬件地址和IP地址的映射问题。

RARP是将MAC物理地址转换成IP地址。

## 5.4 传输层

传输层功能：建立端口到端口的通信

传输层需要有两种不同的运输协议，即面向连接的 TCP 和无连接的 UDP。

> 端口：我们通过IP和Mac找到了一台特定的主机，如何标识这台主机上的应用程序，答案就是端口，端口即应用程序与网卡关联的编号。

有了MAC地址和IP地址，我们已经可以在互联网上任意两台主机上建立通信。

接下来的问题是，同一台主机上有许多程序都需要用到网络，比如，你一边浏览网页，一边与朋友在线聊天。当一个数据包从互联网上发来的时候，你怎么知道，它是表示网页的内容，还是表示在线聊天的内容？即我们还需要一个参数，表示这个数据包到底供那个程序（进程）使用。这个参数就叫做“端口”（port）,他其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。

“端口”是0到65535之间的一个整数，正好16个二进制位。0到1023的端口被系统占用，用户只能选用大于1023的端口。不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。

“传输层”的功能，就是建立“端口到端口”的通信，相比之下，“网络层”的功能是建立“主机到主机”的通信，只要确定主机和端口，我们就能实现程序之间的交流。

**UDP协议**

在数据包中加入端口信息，需要新的协议，最简单的实现叫做UDP协议，他的格式几乎就是在数据前面，加上端口号。

UDP数据包，也是由“标头”和“数据”两部分组成。“标头”部分主要定义了发出端口和接受端口，“数据”部分就是具体的内容。然后把整个UDP数据包放入IP数据包的“数据”部分，IP数据包又是放在以太网数据包之中的，所以整个以太网数据包现在变成了下面这样：

![](D:\Java\笔记\图片\1-11【网络编程】\UDP协议.jpg)



UDP数据包非常简单，“标头”部分一共有8个字节，总长度不超过65535字节，正好放进一个IP数据包。

**TCP协议**

UDP协议的优点是比较简单，容易实现，但是可靠性较差，一旦数据包发出，无法知道对方是否收到。为了解决这个问题，提高网络可靠性，TCP协议就诞生了。这个协议非常复杂，但可以近似认为，它就是有确认机制的UDP协议，每发出一个数据包都要求确认，如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。

因此，TCP协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。

TCP数据包和UDP数据包一样，都是内嵌在IP数据包的"数据"部分。TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。

TCP协议:

- TCP 是面向连接的传输层协议。
- 每一条 TCP 连接只能有两个端点(endpoint)，每一条 TCP 连接只能是点对点的（一对一）。
- TCP 提供可靠交付的服务。
- TCP 提供全双工通信。
- 面向字节流。

UDP协议:

- UDP 是无连接的，即发送数据之前不需要建立连接。
- UDP 使用尽最大努力交付，即不保证可靠交付，同时也不使用拥塞控制。
- UDP 是面向报文的。UDP 没有拥塞控制，很适合多媒体通信的要求。
- UDP 支持一对一、一对多、多对一和多对多的交互通信。
- UDP 的首部开销小，只有 8 个字节。

## 5.5 应用层

应用层收到传输层的数据，接下来就要进行解读，由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。“应用层”的作用，就是规定应用程序的数据格式。

举例来说，TCP协议可以为各种各样的程序传递数据，比如Email、WWW、FTP等等。那么，必须有不同协议规定电子邮件、网页、FTP数据的格式，这些应用程序协议就构成了"应用层"。这是最高的一层，直接面对用户。它的数据就放在TCP数据包的"数据"部分。因此，现在的以太网的数据包就变成下面这样。

![](D:\Java\笔记\图片\1-11【网络编程】\应用层.jpg)

我们常见应用层的网络服务协议有：HTTP，HTTPS，FTP，POP3、SMTP等。

**HTTP协议**

HTTP 协议的特点：

1. HTTP 允许传输任意类型的数据。传输的类型由 `Content-Type` 加以标记。
2. 无状态。对于客户端每次发送的请求，服务器都认为是一个新的请求，上一次会话和下一次会话之间没有联系。
3. 支持客户端/服务器模式。

HTTP 报文格式：

* HTTP 请求由请求行、请求头部、空行和请求体四个部分组成。

  - 请求行：包括请求方法，访问的资源 URL，使用的 HTTP 版本。`GET`和`POST`是最常见的 HTTP 方法，除此以外还包括`DELETE、HEAD、OPTIONS、PUT、TRACE`。

  - 请求头：格式为“属性名:属性值”，服务端根据请求头获取客户端的信息，主要有`cookie、host、connection、accept-language、accept-encoding、user-agent`。

  - 请求体：用户的请求数据如用户名、密码等。


* HTTP 响应也由四个部分组成，分别是：状态行、响应头、空行和响应体。

  - 状态行：协议版本，状态码及状态描述。

  - 响应头：响应头字段主要有`connection、content-type、content-encoding、content-length、set-cookie、Last-Modified、Cache-Control、Expires`。

  - 响应体：服务器返回给客户端的内容。


HTTP 状态码：

![](D:\Java\笔记\图片\1-11【网络编程】\HTTP 状态码.png)

HTTP1.0 和 HTTP1.1 的区别：

- 长连接：HTTP1.0 默认使用短连接，每次请求都需要建立新的 TCP 连接，连接不能复用。HTTP1.1 支持长连接，复用 TCP 连接，允许客户端通过同一连接发送多个请求。不过，这个优化策略也存在问题，当一个队头的请求不能收到响应的资源时，它将会阻塞后面的请求。这就是“队头阻塞”问题。
- 断点续传：HTTP1.0 不支持断点续传。HTTP1.1 新增了 range 字段，用来指定数据字节位置，支持断点续传。
- 错误状态响应码：在 HTTP1.1 中新增了 24 个错误状态响应码，如`409（Conflict）`表示请求的资源与资源的当前状态发生冲突、`410（Gone）`表示服务器上的某个资源被永久性的地删除。
- Host 头处理：在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名。到了 HTTP1.1 时代，虚拟主机技术发展迅速，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个 IP 地址，故 HTTP1.1 增加了 HOST 信息。

HTTP2.0 相比 HTTP1.1 支持的特性：

- 新的二进制格式：HTTP1.1 基于文本格式传输数据；HTTP2.0 采用二进制格式传输数据，解析更高效。
- 多路复用：在一个连接里，允许同时发送多个请求或响应，并且这些请求或响应能够并行地传输而不被阻塞，避免 HTTP1.1 出现的“队头堵塞”问题。
- 头部压缩，HTTP1.1 的 header 带有大量信息，而且每次都要重复发送；HTTP2.0 把 header 从数据中分离，并封装成头帧和数据帧，使用特定算法压缩头帧，有效减少头信息大小。并且 HTTP2.0 在客户端和服务器端记录了之前发送的键值对，对于相同的数据，不会重复发送。比如请求 a 发送了所有的头信息字段，请求 b 则只需要发送差异数据，这样可以减少冗余数据，降低开销。
- 服务端推送：HTTP2.0 允许服务器向客户端推送资源，无需客户端发送请求到服务器获取。

**HTTPS协议**

HTTPS 原理：首先是 TCP 三次握手，然后客户端发起一个 HTTPS 连接建立请求，客户端先发一个`Client Hello`的包，然后服务端响应`Server Hello`，接着再给客户端发送它的证书，然后双方经过密钥交换，最后使用交换的密钥加解密数据。

- 协商加密算法 。在`Client Hello`里面客户端会告知服务端自己当前的一些信息，包括客户端要使用的 TLS 版本，支持的加密算法，要访问的域名，给服务端生成的一个随机数（Nonce）等。需要提前告知服务器想要访问的域名以便服务器发送相应的域名的证书过来。
- 服务端响应`Server Hello`，告诉客户端服务端选中的加密算法。

- 接着服务端给客户端发来了 2 个证书。第二个证书是第一个证书的签发机构（CA）的证书。

- 客户端使用证书的认证机构 CA 公开发布的 RSA 公钥对该证书进行验证，下图表明证书认证成功。

- 验证通过之后，浏览器和服务器通过密钥交换算法产生共享的对称密钥。

- 开始传输数据，使用同一个对称密钥来加解密。

接下来详细介绍一下：

1. 协商加密算法 。在`Client Hello`里面客户端会告知服务端自己当前的一些信息，包括客户端要使用的 TLS 版本，支持的加密算法，要访问的域名，给服务端生成的一个随机数（Nonce）等。需要提前告知服务器想要访问的域名以便服务器发送相应的域名的证书过来。

   ![图片](D:\Java\笔记\图片\1-11【网络编程】\0-0)

2. 服务端响应`Server Hello`，告诉客户端服务端选中的加密算法。

   ![图片](D:\Java\笔记\图片\1-11【网络编程】\0-1)

3. 接着服务端给客户端发来了 2 个证书。第二个证书是第一个证书的签发机构（CA）的证书。

   ![图片](D:\Java\笔记\图片\1-11【网络编程】\0-2)

4. 客户端使用证书的认证机构 CA 公开发布的 RSA 公钥对该证书进行验证，下图表明证书认证成功。

   ![图片](D:\Java\笔记\图片\1-11【网络编程】\0-3)

5. 验证通过之后，浏览器和服务器通过密钥交换算法产生共享的对称密钥。

   ![图片](D:\Java\笔记\图片\1-11【网络编程】\0-4)

   ![图片](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)

6. 开始传输数据，使用同一个对称密钥来加解密。

   ![](D:\Java\笔记\图片\1-11【网络编程】\0-5)

**HTTP与HTTS**

1. HTTP 是超文本传输协议，信息是明文传输；HTTPS 则是具有安全性的 ssl 加密传输协议。
2. HTTP 和 HTTPS 用的端口不一样，HTTP 端口是 80，HTTPS 是 443。
3. HTTPS 协议需要到 CA 机构申请证书，一般需要一定的费用。
4. HTTP 运行在 TCP 协议之上；HTTPS 运行在 SSL 协议之上，SSL 运行在 TCP 协议之上。





# 第六章 网络编程基础知识

## 6.1 什么是数字证书

服务端可以向证书颁发机构 CA 申请证书，以避免中间人攻击（防止证书被篡改）。证书包含三部分内容：证书内容、证书签名算法和签名，签名是为了验证身份。

![](D:\Java\笔记\图片\1-11【网络编程】\数字证书.png)

服务端把证书传输给浏览器，浏览器从证书里取公钥。证书可以证明该公钥对应本网站。

**数字签名的制作过程**：

1. CA 使用证书签名算法对证书内容进行 hash 运算。
2. 对 hash 后的值用 CA 的私钥加密，得到数字签名。

**浏览器验证过程**：

1. 获取证书，得到证书内容、证书签名算法和数字签名。
2. 用 CA 机构的公钥对数字签名解密（由于是浏览器信任的机构，所以浏览器会保存它的公钥）。
3. 用证书里的签名算法对证书内容进行 hash 运算。
4. 比较解密后的数字签名和对证书内容做 hash 运算后得到的哈希值，相等则表明证书可信。

## 6.2 DNS 域名解析

**DNS（Domain Name System）是域名系统的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，用于 TCP/IP 网络。**

通常我们有两种方式识别主机：**通过主机名或者 IP 地址**。人们喜欢便于记忆的主机名表示，而路由器则喜欢定长的、有着层次结构的 IP 地址。为了满足这些不同的偏好，我们就需要一种能够进行主机名到IP 地址转换的目录服务，**域名系统作为将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。**

因此，即使不使用域名也可以通过IP地址来寻址目的主机，但域名与IP地址相比，便于人们记忆。因此对于大多数网络应用，我们一般使用域名来访问目的主机，而不是直接使用IP地址来访问。

------

当我们在浏览器地址栏中输入某个Web服务器的域名时。用户主机首先用户主机会首先在自己的DNS高速缓存中查找该域名所应的IP地址。

如果没有找到，则会向网络中的某台DNS服务器查询，DNS服务器中有域名和IP地映射关系的数据库。当DNS服务器收到DNS查询报文后，在其数据库中查询，之后将查询结果发送给用户主机。

现在，用户主机中的浏览器可以通过Web服务器的IP地址对其进行访问了。

### 域名的层级关系

层级关系特点：

- 因特网采用层次树状结构的域名结构

- 域名的结构由若干个分量组成，各分量之间用“点”隔开，分别代表不同级别的域名。

- - 每一级的域名都由英文字母和数字组成，不超过63个字符，不区分大小写字母。
  - 级别最低的域名写在最左边，而级别最高的顶级域名写在最右边。
  - 完整的域名不超过255个字符。

- 域名系统既不规定一个域名需要包含多少个下级域名，也不规定每一级的域名代表什么意思。

- 各级域名由其上一级的域名管理机构管理，而最高的顶级域名则由因特网名称与数字地址分配机构ICANN进行管理。

域名服务器可以划分为以下四种不同的类型：

- **根域名服务器** 根域名服务器是最高层次的域名服务器。每个根域名服务器都知道所有的顶级域名服务器的域名及其IP地址。因特网上共有13个不同IP地址的根域名服务器。当本地域名服务器向根域名服务器发出查询请求时，路由器就把查询请求报文转发到离这个DNS客户最近的一个根域名服务器。这就加快了DNS的查询过程，同时也更合理地利用了因特网的资源。
- **顶级域名服务器** 这些域名服务器负责管理在该顶级域名服务器注册的所有二级域名。当收到DNS查询请求时就给出相应的回答（可能是最后的结果，也可能是下一级权限域名服务器的IP地址)。
- **权限域名服务器** 这些域名服务器负责管理某个区的域名。每一个主机的域名都必须在某个权限域名服务器处注册登记。因此权限域名服务器知道其管辖的域名与IP地址的映射关系。另外，权限域名服务器还知道其下级域名服务器的地址。
- **本地域名服务器** 本地域名服务器不属于上述的域名服务器的等级结构。当一个主机发出DNS请求报文时，这个报文就首先被送往该主机的本地域名服务器。本地域名服务器起着代理的作用，会将该报文转发到上述的域名服务器的等级结构中。本地域名服务器离用户较近，一般不超过几个路由器的距离，也有可能就在同一个局域网中。本地域名服务器的IP地址需要直接配置在需要域名解析的主机中。

### DNS 域名解析过程

域名解析包含两种查询方式，分别是**递归查询**和**迭代查询**。

#### 递归查询

“递归解析”是最常见也是默认的一种解析方式。在这种解析方式中，如果客户端配置的本地域名服务器（Local DNS服务器）不能解析的话，则后面的查询过程全部**由本地域名服务器代替DNS客户端进行查询**，直到本地域名服务器从权威域名服务器得到了正确的解析结果，然后由本地域名服务器告诉DNS客户端查询的结果。

在整个递归查询过程中，除一开始客户端向本地域名服务器发起查询请求外，其余各个环节均是以本地域名服务器为中心进行迭代查询，DNS客户端一直处于等待状态，直到本地域名服务器发回最终查询结果。相当于，在整个查询环节中本地域名服务器承担了中介代理的角色。

1. 客户端向本机配置的本地域名服务器发起DNS域名查询请求；

2. 本地域名服务器收到请求后，会先查询本地缓存，如果有记录值会直接返回给客户端；如果没有记录，则本地域名服务器会向根域名服务器发起请求；

3. 根域名服务器收到请求后，会根据所要查询域名中的后缀将所对应的顶级域名服务器（如.com、.cn等）返回给本地域名服务器；

4. 本地域名服务器根据返回结果向所对应的顶级域名服务器发起查询请求；

5. 对应的顶级域名服务器在收到DNS查询请求后，也是先查询自己的缓存，如果有所请求域名的解析记录，则会直接将记录返回给本地域名服务器，然后本地域名服务器再将记录返回给客户端，完成整个DNS解析过程。

6. 如果顶级域名服务器没有记录值，就会将二级域名对应的服务器地址返回给本地域名服务器，本地域名服务器再次对二级域名服务器发起请求，如此类推，直到最终对应区域的权威域名服务器返回结果给本地域名服务器。然后本地域名服务器将记录值返回给DNS客户端，同时缓存本地查询记录，以便在TTL值内用户再次查询时直接将记录返回给客户端。

#### 迭代查询

从上面的介绍中我们看到了，递归查询除在一开始客户端发起查询请求外，其他环节都是由本地域名服务器代替客户端进行的。而**迭代查询则是指所有查询工作全部由客户端自己进行**，除此之外，整个查询路径和步骤与递归查询没有太大区别。

首先客户端向本地域名服务器发起请求，如果本地域名服务器没有缓存记录，客户端便会依次对根域名服务器、顶级域名服务器和二级域名服务器等发起迭代查询，直到获得最终的查询结果。

在以下条件之一满足时，就会采用迭代解析方式：

1. 在查询本地域名服务器时，如果客户端的请求报文中没有申请使用递归查询，即在DNS请求报文中的RD字段没有设置为1。

2. 客户端在DNS请求报文中申请使用递归查询，但所配置的本地域名服务器禁止使用递归查询，即在应答DNS报文头部的RA字段设置为0。

由于递归查询对于被查询的域名服务器负担太大，通常采用以下模式：**从请求主机到本地域名服务器的查询是递归查询，而其余的查询是迭代查询。**

### 高速缓存

为了提高DNS的查询效率，并减轻根域名服务器的负荷和减少因特网上的DNS查询报文数量，在域名服务器中广泛地使用了**高速缓存**。高速缓存用来存放最近查询过的域名以及从何处获得域名映射信息的记录。

由于域名到IP地址的映射关系并不是永久不变，为保持高速缓存中的内容正确，域名服务器**应为每项内容设置计时器并删除超过合理时间的项**（例如，每个项目只存放两天)。

不但在本地域名服务器中需要高速缓存，在用户主机中也很需要。许多用户主机在启动时从本地域名服务器下载域名和IP地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到域名时才向域名服务器查询。同理，主机也需要保持高速缓存中内容的正确性。

如果**本地域名服务器**不久前已经有用户查询过域名为y.abc.com的IP地址，则本地域名服务器的高速缓存中应该存有该域名对应的IP地址。因此，直接把高速缓存中存放的上次查询结果(即y.abc.com的IP地址)告诉用户。

### DNS相关面试问题

**DNS为什么用UDP？**

更正确的答案是 DNS 既使用 TCP 又使用 UDP。当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP。

当客户端向 DNS 服务器查询域名 ( 域名解析) 的时候，一般返回的内容不会超过 UDP 报文的最大长度，即 512 字节。用 UDP 传输时，不需要经过 TCP 三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。

**递归查询和递归查询区别？**

- **递归查询:** 如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户端的身份，向其他根域名服务器继续发出查询请求报文，即替主机继续查询，而不是让主机自己进行下一步查询。
- **迭代查询：** 当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP 地址，要么告诉本地服务器下一步应该找哪个域名服务器进行查询，然后让本地服务器进行后续的查询。

**讲讲DNS解析过程？**

1. 浏览器搜索自己的 DNS 缓存。
2. 若没有，则搜索操作系统中的 DNS 缓存和 hosts 文件。
3. 若没有，则操作系统将域名发送至本地域名服务器，本地域名服务器查询自己的 DNS 缓存，查找成功则返回结果，否则依次向根域名服务器、顶级域名服务器、权限域名服务器发起查询请求，最终返回 IP 地址给本地域名服务器。
4. 本地域名服务器将得到的 IP 址返回给操作系统，同时自己也将 IP 地址缓存起来。
5. 操作系统将 IP 地址返回给浏览器，同时自己也将 IP 地址缓存起来。
6. 浏览器得到域名对应的 IP 地址。

## 6.3 浏览器输入URL返回页面过程

1. 解析域名，找到主机 IP。
2. 浏览器利用 IP 直接与网站主机通信，三次握手，建立 TCP 连接。浏览器会以一个随机端口向服务端的 web 程序 80 端口发起 TCP 的连接。
3. 建立 TCP 连接后，浏览器向主机发起一个 HTTP 请求。
4. 服务器响应请求，返回响应数据。
5. 浏览器解析响应内容，进行渲染，呈现给用户。

![图片](D:\Java\笔记\图片\1-11【网络编程】\10)

## 6.4 Cookie 和 Session 的区别

- **作用范围不同**，Cookie 保存在客户端，Session 保存在服务器端。
- **有效期不同**，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。
- **隐私策略不同**，Cookie 存储在客户端，容易被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
- **存储大小不同**， 单个 Cookie 保存的数据不能超过 4K；对于 Session 来说存储没有上限，但出于对服务器的性能考虑，Session 内不要存放过多的数据，并且需要设置 Session 删除机制。

## 6.5 什么是对称加密和非对称加密

**对称加密**：通信双方使用相同的密钥进行加密。特点是加密速度快，但是缺点是密钥泄露会导致密文数据被破解。常见的对称加密有`AES`和`DES`算法。

**非对称加密**：它需要生成两个密钥，公钥和私钥。公钥是公开的，任何人都可以获得，而私钥是私人保管的。公钥负责加密，私钥负责解密；或者私钥负责加密，公钥负责解密。这种加密算法安全性更高，但是计算量相比对称加密大很多，加密和解密都很慢。常见的非对称算法有`RSA`和`DSA`。

## 6.7 粘包

TCP/IP协议簇建立了互联网中通信协议的概念模型，该协议簇中的两个主要协议就是 TCP 和 IP 协议。TCP/ IP 协议簇中的 TCP 协议能够保证数据段（Segment）的可靠性和顺序，有了可靠的传输层协议之后，应用层协议就可以直接使用 TCP 协议传输数据，不在需要关心数据段的丢失和重复问题。

IP协议解决了数据包（Packet）的路由和传输，上层的 TCP 协议不再关注路由和寻址，那么 TCP 协议解决的是传输的可靠性和顺序问题，上层不需要关心数据能否传输到目标进程，只要写入 TCP 协议的缓冲区的数据，协议栈几乎都能保证数据的送达。

当应用层协议使用 TCP 协议传输数据时，TCP 协议可能会将应用层发送的数据分成多个包依次发送，而数据的接收方收到的数据段可能有多个『应用层数据包』组成，所以当应用层从 TCP 缓冲区中读取数据时发现粘连的数据包时，需要对收到的数据进行拆分。

### 什么是粘包

粘包：多个数据包被连续存储于连续的缓存中，在对数据包进行读取时由于无法确定发生方的发送边界，而采用某一估测值大小来进行数据读出，若双方的size不一致时就会使指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

指 TCP 协议中，**发送方发送的若干数据到接收方接收时粘成一包,从接收缓冲区来看,后一包数据的头,紧接着前一包数据的尾.**

### 出现原因

出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。

先说简单的接收方原因, 接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。

再说由发送导致的粘包, 这个比较有意思.

粘包并不是 TCP 协议造成的，它的出现是因为应用层协议设计者对 TCP 协议的错误理解，忽略了 TCP 协议的定义并且缺乏设计应用层协议的经验。我们将从 TCP 协议以及应用层协议出发，分析我们经常提到的 TCP 协议中的粘包是如何发生的：

- TCP 协议是面向字节流的协议，它可能会组合或者拆分应用层协议的数据；
- 应用层协议的没有定义消息的边界导致数据的接收方无法拼接数据；

TCP 协议是面向连接的、可靠的、基于字节流的传输层通信协议，应用层交给 TCP 协议的数据并不会以消息为单位向目的主机传输，这些数据在某些情况下会被组合成一个数据段发送给目标的主机。

Nagle 算法是一种通过减少数据包的方式提高 TCP 传输性能的算法。因为网络带宽有限，它不会将小的数据块直接发送到目的主机，而是会在本地缓冲区中等待更多待发送的数据，这种批量发送数据的策略虽然会影响实时性和网络延迟，但是能够降低网络拥堵的可能性并减少额外开销。

在早期的互联网中，Telnet 是被广泛使用的应用程序，然而使用 Telnet 会产生大量只有 1 字节负载的有效数据，每个数据包都会有 40 字节的额外开销，带宽的利用率只有 ~2.44%，Nagle 算法就是在当时的这种场景下设计的。

当应用层协议通过 TCP 协议传输数据时，实际上待发送的数据先被写入了 TCP 协议的缓冲区，如果用户开启了 Nagle 算法，那么 TCP 协议可能不会立刻发送写入的数据，它会等待缓冲区中数据超过最大数据段（MSS）或者上一个数据段被 ACK 时才会发送缓冲区中的数据。
![nagle-algorithm](D:\Java\笔记\图片\1-11【网络编程】\format,png)

**图 2 - Nagle 算法**

Nagle 算法确实能够在数据包较小时提高网络带宽的利用率并减少 TCP 和 IP 协议头带来的额外开销，但是使用该算法也可能会导致应用层协议多次写入的数据被合并或者拆分发送，当接收方从 TCP 协议栈中读取数据时会发现不相关的数据出现在了同一个数据段中，应用层协议可能没有办法对它们进行拆分和重组。

除了 Nagle 算法之外，TCP 协议栈中还有另一个用于延迟发送数据的选项 `TCP_CORK`，如果我们开启该选项，那么当发送的数据小于 MSS 时，TCP 协议就会延迟 200ms 发送该数据或者等待缓冲区中的数据超过 MSS。

无论是 `TCP_NODELAY` 还是 `TCP_CORK`，它们都会通过延迟发送数据来提高带宽的利用率，它们会对应用层协议写入的数据进行拆分和重组，而这些机制和配置能够出现的最重要原因是 — TCP 协议是基于字节流的协议，其本身没有数据包的概念，不会按照数据包发送数据。

### 如何解决粘包

如果我们系统性地学习过 TCP 协议以及基于 TCP 的应用层协议设计，那么设计一个能够被 TCP 协议栈任意拆分和组装数据包的应用层协议就不会有什么问题。既然 TCP 协议是基于字节流的，这其实就意味着应用层协议要自己划分消息的边界。

如果我们能在应用层协议中定义消息的边界，那么无论 TCP 协议如何对应用层协议的数据包进程拆分和重组，接收方都能根据协议的规则恢复对应的消息。在应用层协议中，最常见的两种解决方案就是**基于长度或者基于终结符**（Delimiter）。

![message-framing](D:\Java\笔记\图片\1-11【网络编程】\format2,png)

**图 3 - 实现消息边界的方法**

基于长度的实现有两种方式，一种是使用固定长度，所有的应用层消息都使用统一的大小，另一种方式是使用不固定长度，但是需要在应用层协议的协议头中增加表示负载长度的字段，这样接收方才可以从字节流中分离出不同的消息，HTTP 协议的消息边界就是 **基于长度+负载长度** 实现的：

```xml
HTTP/1.1 200 OK
Content-Type: text/html; charset=UTF-8
Content-Length: 138
...
Connection: close
 
<html>
  <head>
    <title>An Example Page</title>
  </head>
  <body>
    <p>Hello World, this is a very simple HTML document.</p>
  </body>
</html>
```

在上述 HTTP 消息中，我们使用 `Content-Length` 头表示 HTTP 消息的负载大小，当应用层协议解析到足够的字节数后，就能从中分离出完整的 HTTP 消息，无论发送方如何处理对应的数据包，我们都可以遵循这一规则完成 HTTP 消息的重组。

虽然知道http-header中有`Content-Length,以为只是一个简单的标记左右,现在才知道是为了解决粘包问题.`

不过 HTTP 协议除了使用基于长度的方式实现边界，也会使用基于终结符的策略，当 HTTP 使用块传输（Chunked Transfer）机制时，HTTP 头中就不再包含 `Content-Length` 了，它会使用负载大小为 0 的 HTTP 消息作为终结符表示消息的边界。

还有在使用post进行表单上传文件时, 会有一个boundary字符串(大概张这样, --ZnGpDtePMx0KrHh_G0X99Yef9r8JZsRJSXC), 这个也是作为文件的一个分隔符, 也可以说是基于终结符策略的.

当然除了这两种方式之外，我们可以基于特定的规则实现消息的边界，例如：使用 TCP 协议发送 JSON 数据，接收方可以根据接收到的数据是否能够被解析成合法的 JSON 判断消息是否终结。

### 总结

TCP 协议粘包问题是因为应用层协议开发者的错误设计导致的，他们忽略了 TCP 协议数据传输的核心机制 — 基于字节流，其本身不包含消息、数据包等概念，所有数据的传输都是流式的，需要应用层协议自己设计消息的边界，即消息帧（Message Framing），我们重新回顾一下粘包问题出现的核心原因：

1. TCP 协议是基于字节流的传输层协议，其中不存在消息和数据包的概念；
2. 应用层协议可以使用基于长度或者基于终结符的消息边界，解决多个消息的粘连；

为什么会产生粘包和拆包呢？

- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；
- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；
- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；
- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 > MSS。

解决方案：

- 发送端将每个数据包封装为固定长度
- 在数据尾部增加特殊字符进行分割
- 将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小固定，且有一个字段声明内容体的大小。

## 6.8 KeepAlive

首先，我们要明确我们谈的是**TCP**的 **`KeepAlive`** 还是**HTTP**的 **`Keep-Alive`**。TCP的KeepAlive和HTTP的Keep-Alive**是完全不同的概念，不能混为一谈**。

实际上HTTP的KeepAlive写法是`Keep-Alive`，跟TCP的`KeepAlive`写法上也有不同。

- TCP的**keepalive**是侧重在保持客户端和服务端的连接，一方会不定期发送心跳包给另一方，当一方端掉的时候，没有断掉的定时发送几次**心跳包**，如果间隔发送几次，对方都返回的是RST，而不是ACK，那么就释放当前链接。

  设想一下，如果tcp层没有keepalive的机制，一旦一方断开连接却没有发送FIN给另外一方的话，那么另外一方会一直以为这个连接还是存活的，几天，几月。那么这对服务器资源的影响是很大的。

- HTTP的**keep-alive**一般我们都会带上中间的**横杠**，普通的http连接是客户端连接上服务端，然后结束请求后，由客户端或者服务端进行http连接的关闭。下次再发送请求的时候，客户端再发起一个连接，传送数据，关闭连接。这么个流程反复。

  但是一旦客户端发送`connection:keep-alive`头给服务端，且服务端也接受这个keep-alive的话，两边对上暗号，这个连接就可以复用了，一个http处理完之后，另外一个http数据直接从这个连接走了。减少新建和断开TCP连接的消耗。

二者的作用简单来说：

> HTTP协议的Keep-Alive意图在于短时间内连接复用，希望可以短时间内在同一个连接上进行多次请求/响应。
>
> TCP的KeepAlive机制意图在于保活、心跳，检测连接错误。当一个TCP连接两端长时间没有数据传输时(通常默认配置是2小时)，发送keepalive探针，探测链接是否存活。

**总之，记住HTTP的Keep-Alive和TCP的KeepAlive不是一回事。**

**tcp的keepalive是在ESTABLISH状态的时候，双方如何检测连接的可用行。**

**而http的keep-alive说的是如何避免进行重复的TCP三次握手和四次挥手的环节。**

### TCP的KeepAlive

**为什么要有KeepAlive**

在谈KeepAlive之前，我们先来了解下简单TCP知识。首先要明确的是在TCP层是没有“请求”一说的，经常听到在TCP层发送一个请求，这种说法是错误的。

TCP是一种通信的方式，“请求”一词是事务上的概念，HTTP协议是一种事务协议，如果说发送一个HTTP请求，这种说法就没有问题。也经常听到面试官反馈有些面试运维的同学，基本的TCP三次握手的概念不清楚，面试官问TCP是如何建立链接，面试者上来就说，假如我是客户端我发送一个请求给服务端，服务端发送一个请求给我。。。

这种一听就知道对TCP基本概念不清楚。下面是通过wireshark抓取的一个TCP建立握手的过程。（命令行基本上用TCPdump,后面我们还会用这张图说明问题）:

![](D:\Java\笔记\图片\1-11【网络编程】\13.jpg)

现在只要看前3行，这就是TCP三次握手的完整建立过程，第一个报文SYN从发起方发出，第二个报文SYN,ACK是从被连接方发出，第三个报文ACK确认对方的SYN，ACK已经收到，如下图：

![](D:\Java\笔记\图片\1-11【网络编程】\14.webp)

但是数据实际上并没有传输，请求是有数据的，第四个报文才是数据传输开始的过程，wireshark把第四个报文解析成HTTP协议，HTTP协议的GET方法和URI也解析出来，所以说TCP层是没有请求的概念，HTTP协议是事务性协议才有请求的概念，TCP报文承载HTTP协议的请求(Request)和响应(Response)。

现在才是开始说明为什么要有KeepAlive。链接建立之后，如果应用程序或者上层协议一直不发送数据，或者隔很长时间才发送一次数据，当链接很久没有数据报文传输时如何去确定对方还在线，到底是掉线了还是确实没有数据传输，链接还需不需要保持，这种情况在TCP协议设计中是需要考虑到的。

TCP协议通过一种巧妙的方式去解决这个问题，当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明对方还在线，链接可以继续保持，如果对方没有报文返回，并且重试了多次之后则认为链接丢失，没有必要保持链接。

**怎么开启KeepAlive？**

KeepAlive并不是默认开启的，在Linux系统上没有一个全局的选项去开启TCP的KeepAlive。需要开启KeepAlive的应用必须在TCP的socket中单独开启。Linux Kernel有三个选项影响到KeepAlive的行为：

> - tcp_keepalive_time 7200// 距离上次传送数据多少时间未收到新报文判断为开始检测，单位秒，默认7200s
> - tcp_keepalive_intvl 75// 检测开始每多少时间发送心跳包，单位秒，默认75s
> - tcp_keepalive_probes 9// 发送几次心跳包对方未响应则close连接，默认9次

TCP socket也有三个选项和内核对应，通过setsockopt系统调用针对单独的socket进行设置：

> - TCPKEEPCNT: 覆盖 tcpkeepaliveprobes
> - TCPKEEPIDLE: 覆盖 tcpkeepalivetime
> - TCPKEEPINTVL: 覆盖 tcpkeepalive_intvl

举个例子，以我的系统默认设置为例，kernel默认设置的tcpkeepalivetime是7200s, 如果我在应用程序中针对socket开启了KeepAlive,然后设置的TCP_KEEPIDLE为60，那么TCP协议栈在发现TCP链接空闲了60s没有数据传输的时候就会发送第一个探测报文。

**KeepAlive的不足和局限性**

其实，tcp自带的keepalive还是有些不足之处的。

keepalive只能检测连接是否存活，不能检测连接是否可用。例如，某一方发生了死锁，无法在连接上进行任何读写操作，但是操作系统仍然可以响应网络层keepalive包。

TCP keepalive 机制依赖于操作系统的实现,灵活性不够，默认关闭，且默认的 keepalive 心跳时间是 两个小时, 时间较长。代理(如socks proxy)、或者负载均衡器，会让tcp KeepAlive失效

### HTTP的Keep-Alive

通常一个网页可能会有很多组成部分，除了文本内容，还会有诸如：js、css、图片等静态资源，有时还会异步发起AJAX请求。只有所有的资源都加载完毕后，我们看到网页完整的内容。然而，一个网页中，可能引入了几十个js、css文件，上百张图片，如果每请求一个资源，就创建一个连接，然后关闭，代价实在太大了。

基于此背景，我们希望连接能够在短时间内得到复用，在加载同一个网页中的内容时，尽量的复用连接，这就是HTTP协议中keep-alive属性的作用。

> - HTTP的Keep-Alive是**HTTP1.1**中**默认开启**的功能。通过headers设置"`Connection: close` "关闭
> - 在HTTP1.0中是**默认关闭**的。通过headers设置"`Connection: Keep-Alive`"开启。

对于客户端来说，不论是浏览器，还是手机App，或者我们直接在Java代码中使用`HttpUrlConnection`，只是负责在请求头中设置Keep-Alive。Keep-Alive属性保持连接的**时间长短是由服务端决定的**，通常配置都是在**几十秒左右。**

开启HTTP Keep-Alive之后，能复用已有的TCP链接，当前一个请求已经响应完毕，服务器端没有立即关闭TCP链接，而是等待一段时间接收浏览器端可能发送过来的第二个请求，通常浏览器在第一个请求返回之后会立即发送第二个请求，如果某一时刻只能有一个链接，同一个TCP链接处理的请求越多，开启KeepAlive能节省的TCP建立和关闭的消耗就越多。

当然通常会启用多个链接去从服务器器上请求资源，但是开启了Keep-Alive之后，仍然能加快资源的加载速度。HTTP/1.1之后默认开启Keep-Alive, 在HTTP的头域中增加Connection选项。当设置为`Connection:keep-alive`表示开启，设置为`Connection:close`表示关闭。

