# 第六章 网络编程基础知识

## 6.1 什么是数字证书

服务端可以向证书颁发机构 CA 申请证书，以避免中间人攻击（防止证书被篡改）。证书包含三部分内容：证书内容、证书签名算法和签名，签名是为了验证身份。

![](D:\Java\笔记\图片\1-11【网络编程】\数字证书.png)

服务端把证书传输给浏览器，浏览器从证书里取公钥。证书可以证明该公钥对应本网站。

**数字签名的制作过程**：

1. CA 使用证书签名算法对证书内容进行 hash 运算。
2. 对 hash 后的值用 CA 的私钥加密，得到数字签名。

**浏览器验证过程**：

1. 获取证书，得到证书内容、证书签名算法和数字签名。
2. 用 CA 机构的公钥对数字签名解密（由于是浏览器信任的机构，所以浏览器会保存它的公钥）。
3. 用证书里的签名算法对证书内容进行 hash 运算。
4. 比较解密后的数字签名和对证书内容做 hash 运算后得到的哈希值，相等则表明证书可信。

## 6.2 DNS 域名解析

**DNS（Domain Name System）是域名系统的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，用于 TCP/IP 网络。**

通常我们有两种方式识别主机：**通过主机名或者 IP 地址**。人们喜欢便于记忆的主机名表示，而路由器则喜欢定长的、有着层次结构的 IP 地址。为了满足这些不同的偏好，我们就需要一种能够进行主机名到IP 地址转换的目录服务，**域名系统作为将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。**

因此，即使不使用域名也可以通过IP地址来寻址目的主机，但域名与IP地址相比，便于人们记忆。因此对于大多数网络应用，我们一般使用域名来访问目的主机，而不是直接使用IP地址来访问。

------

当我们在浏览器地址栏中输入某个Web服务器的域名时。用户主机首先用户主机会首先在自己的DNS高速缓存中查找该域名所应的IP地址。

如果没有找到，则会向网络中的某台DNS服务器查询，DNS服务器中有域名和IP地映射关系的数据库。当DNS服务器收到DNS查询报文后，在其数据库中查询，之后将查询结果发送给用户主机。

现在，用户主机中的浏览器可以通过Web服务器的IP地址对其进行访问了。

### 域名的层级关系

层级关系特点：

- 因特网采用层次树状结构的域名结构

- 域名的结构由若干个分量组成，各分量之间用“点”隔开，分别代表不同级别的域名。

- - 每一级的域名都由英文字母和数字组成，不超过63个字符，不区分大小写字母。
  - 级别最低的域名写在最左边，而级别最高的顶级域名写在最右边。
  - 完整的域名不超过255个字符。

- 域名系统既不规定一个域名需要包含多少个下级域名，也不规定每一级的域名代表什么意思。

- 各级域名由其上一级的域名管理机构管理，而最高的顶级域名则由因特网名称与数字地址分配机构ICANN进行管理。

域名服务器可以划分为以下四种不同的类型：

- **根域名服务器** 根域名服务器是最高层次的域名服务器。每个根域名服务器都知道所有的顶级域名服务器的域名及其IP地址。因特网上共有13个不同IP地址的根域名服务器。当本地域名服务器向根域名服务器发出查询请求时，路由器就把查询请求报文转发到离这个DNS客户最近的一个根域名服务器。这就加快了DNS的查询过程，同时也更合理地利用了因特网的资源。
- **顶级域名服务器** 这些域名服务器负责管理在该顶级域名服务器注册的所有二级域名。当收到DNS查询请求时就给出相应的回答（可能是最后的结果，也可能是下一级权限域名服务器的IP地址)。
- **权限域名服务器** 这些域名服务器负责管理某个区的域名。每一个主机的域名都必须在某个权限域名服务器处注册登记。因此权限域名服务器知道其管辖的域名与IP地址的映射关系。另外，权限域名服务器还知道其下级域名服务器的地址。
- **本地域名服务器** 本地域名服务器不属于上述的域名服务器的等级结构。当一个主机发出DNS请求报文时，这个报文就首先被送往该主机的本地域名服务器。本地域名服务器起着代理的作用，会将该报文转发到上述的域名服务器的等级结构中。本地域名服务器离用户较近，一般不超过几个路由器的距离，也有可能就在同一个局域网中。本地域名服务器的IP地址需要直接配置在需要域名解析的主机中。

### DNS 域名解析过程

域名解析包含两种查询方式，分别是**递归查询**和**迭代查询**。

#### 递归查询

“递归解析”是最常见也是默认的一种解析方式。在这种解析方式中，如果客户端配置的本地域名服务器（Local DNS服务器）不能解析的话，则后面的查询过程全部**由本地域名服务器代替DNS客户端进行查询**，直到本地域名服务器从权威域名服务器得到了正确的解析结果，然后由本地域名服务器告诉DNS客户端查询的结果。

在整个递归查询过程中，除一开始客户端向本地域名服务器发起查询请求外，其余各个环节均是以本地域名服务器为中心进行迭代查询，DNS客户端一直处于等待状态，直到本地域名服务器发回最终查询结果。相当于，在整个查询环节中本地域名服务器承担了中介代理的角色。

1. 客户端向本机配置的本地域名服务器发起DNS域名查询请求；

2. 本地域名服务器收到请求后，会先查询本地缓存，如果有记录值会直接返回给客户端；如果没有记录，则本地域名服务器会向根域名服务器发起请求；

3. 根域名服务器收到请求后，会根据所要查询域名中的后缀将所对应的顶级域名服务器（如.com、.cn等）返回给本地域名服务器；

4. 本地域名服务器根据返回结果向所对应的顶级域名服务器发起查询请求；

5. 对应的顶级域名服务器在收到DNS查询请求后，也是先查询自己的缓存，如果有所请求域名的解析记录，则会直接将记录返回给本地域名服务器，然后本地域名服务器再将记录返回给客户端，完成整个DNS解析过程。

6. 如果顶级域名服务器没有记录值，就会将二级域名对应的服务器地址返回给本地域名服务器，本地域名服务器再次对二级域名服务器发起请求，如此类推，直到最终对应区域的权威域名服务器返回结果给本地域名服务器。然后本地域名服务器将记录值返回给DNS客户端，同时缓存本地查询记录，以便在TTL值内用户再次查询时直接将记录返回给客户端。

#### 迭代查询

从上面的介绍中我们看到了，递归查询除在一开始客户端发起查询请求外，其他环节都是由本地域名服务器代替客户端进行的。而**迭代查询则是指所有查询工作全部由客户端自己进行**，除此之外，整个查询路径和步骤与递归查询没有太大区别。

首先客户端向本地域名服务器发起请求，如果本地域名服务器没有缓存记录，客户端便会依次对根域名服务器、顶级域名服务器和二级域名服务器等发起迭代查询，直到获得最终的查询结果。

在以下条件之一满足时，就会采用迭代解析方式：

1. 在查询本地域名服务器时，如果客户端的请求报文中没有申请使用递归查询，即在DNS请求报文中的RD字段没有设置为1。

2. 客户端在DNS请求报文中申请使用递归查询，但所配置的本地域名服务器禁止使用递归查询，即在应答DNS报文头部的RA字段设置为0。

由于递归查询对于被查询的域名服务器负担太大，通常采用以下模式：**从请求主机到本地域名服务器的查询是递归查询，而其余的查询是迭代查询。**

### 高速缓存

为了提高DNS的查询效率，并减轻根域名服务器的负荷和减少因特网上的DNS查询报文数量，在域名服务器中广泛地使用了**高速缓存**。高速缓存用来存放最近查询过的域名以及从何处获得域名映射信息的记录。

由于域名到IP地址的映射关系并不是永久不变，为保持高速缓存中的内容正确，域名服务器**应为每项内容设置计时器并删除超过合理时间的项**（例如，每个项目只存放两天)。

不但在本地域名服务器中需要高速缓存，在用户主机中也很需要。许多用户主机在启动时从本地域名服务器下载域名和IP地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到域名时才向域名服务器查询。同理，主机也需要保持高速缓存中内容的正确性。

如果**本地域名服务器**不久前已经有用户查询过域名为y.abc.com的IP地址，则本地域名服务器的高速缓存中应该存有该域名对应的IP地址。因此，直接把高速缓存中存放的上次查询结果(即y.abc.com的IP地址)告诉用户。

### DNS相关面试问题

**DNS为什么用UDP？**

更正确的答案是 DNS 既使用 TCP 又使用 UDP。当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP。

当客户端向 DNS 服务器查询域名 ( 域名解析) 的时候，一般返回的内容不会超过 UDP 报文的最大长度，即 512 字节。用 UDP 传输时，不需要经过 TCP 三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。

**递归查询和递归查询区别？**

- **递归查询:** 如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户端的身份，向其他根域名服务器继续发出查询请求报文，即替主机继续查询，而不是让主机自己进行下一步查询。
- **迭代查询：** 当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP 地址，要么告诉本地服务器下一步应该找哪个域名服务器进行查询，然后让本地服务器进行后续的查询。

**讲讲DNS解析过程？**

1. 浏览器搜索自己的 DNS 缓存。
2. 若没有，则搜索操作系统中的 DNS 缓存和 hosts 文件。
3. 若没有，则操作系统将域名发送至本地域名服务器，本地域名服务器查询自己的 DNS 缓存，查找成功则返回结果，否则依次向根域名服务器、顶级域名服务器、权限域名服务器发起查询请求，最终返回 IP 地址给本地域名服务器。
4. 本地域名服务器将得到的 IP 址返回给操作系统，同时自己也将 IP 地址缓存起来。
5. 操作系统将 IP 地址返回给浏览器，同时自己也将 IP 地址缓存起来。
6. 浏览器得到域名对应的 IP 地址。

## 6.3 浏览器输入URL返回页面过程

1. 解析域名，找到主机 IP。
2. 浏览器利用 IP 直接与网站主机通信，三次握手，建立 TCP 连接。浏览器会以一个随机端口向服务端的 web 程序 80 端口发起 TCP 的连接。
3. 建立 TCP 连接后，浏览器向主机发起一个 HTTP 请求。
4. 服务器响应请求，返回响应数据。
5. 浏览器解析响应内容，进行渲染，呈现给用户。

![图片](D:\Java\笔记\图片\1-11【网络编程】\10.png)

## 6.4 Cookie 和 Session 的区别

- **作用范围不同**，Cookie 保存在客户端，Session 保存在服务器端。
- **有效期不同**，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。
- **隐私策略不同**，Cookie 存储在客户端，容易被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
- **存储大小不同**， 单个 Cookie 保存的数据不能超过 4K；对于 Session 来说存储没有上限，但出于对服务器的性能考虑，Session 内不要存放过多的数据，并且需要设置 Session 删除机制。

## 6.5 什么是对称加密和非对称加密

**对称加密**：通信双方使用相同的密钥进行加密。特点是加密速度快，但是缺点是密钥泄露会导致密文数据被破解。常见的对称加密有`AES`和`DES`算法。

**非对称加密**：它需要生成两个密钥，公钥和私钥。公钥是公开的，任何人都可以获得，而私钥是私人保管的。公钥负责加密，私钥负责解密；或者私钥负责加密，公钥负责解密。这种加密算法安全性更高，但是计算量相比对称加密大很多，加密和解密都很慢。常见的非对称算法有`RSA`和`DSA`。

## 6.7 粘包

TCP/IP协议簇建立了互联网中通信协议的概念模型，该协议簇中的两个主要协议就是 TCP 和 IP 协议。TCP/ IP 协议簇中的 TCP 协议能够保证数据段（Segment）的可靠性和顺序，有了可靠的传输层协议之后，应用层协议就可以直接使用 TCP 协议传输数据，不在需要关心数据段的丢失和重复问题。

IP协议解决了数据包（Packet）的路由和传输，上层的 TCP 协议不再关注路由和寻址，那么 TCP 协议解决的是传输的可靠性和顺序问题，上层不需要关心数据能否传输到目标进程，只要写入 TCP 协议的缓冲区的数据，协议栈几乎都能保证数据的送达。

当应用层协议使用 TCP 协议传输数据时，TCP 协议可能会将应用层发送的数据分成多个包依次发送，而数据的接收方收到的数据段可能有多个『应用层数据包』组成，所以当应用层从 TCP 缓冲区中读取数据时发现粘连的数据包时，需要对收到的数据进行拆分。

### 什么是粘包

粘包：多个数据包被连续存储于连续的缓存中，在对数据包进行读取时由于无法确定发生方的发送边界，而采用某一估测值大小来进行数据读出，若双方的size不一致时就会使指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

指 TCP 协议中，**发送方发送的若干数据到接收方接收时粘成一包,从接收缓冲区来看,后一包数据的头,紧接着前一包数据的尾.**

### 出现原因

出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。

先说简单的接收方原因, 接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。

再说由发送导致的粘包, 这个比较有意思.

粘包并不是 TCP 协议造成的，它的出现是因为应用层协议设计者对 TCP 协议的错误理解，忽略了 TCP 协议的定义并且缺乏设计应用层协议的经验。我们将从 TCP 协议以及应用层协议出发，分析我们经常提到的 TCP 协议中的粘包是如何发生的：

- TCP 协议是面向字节流的协议，它可能会组合或者拆分应用层协议的数据；
- 应用层协议的没有定义消息的边界导致数据的接收方无法拼接数据；

TCP 协议是面向连接的、可靠的、基于字节流的传输层通信协议，应用层交给 TCP 协议的数据并不会以消息为单位向目的主机传输，这些数据在某些情况下会被组合成一个数据段发送给目标的主机。

Nagle 算法是一种通过减少数据包的方式提高 TCP 传输性能的算法。因为网络带宽有限，它不会将小的数据块直接发送到目的主机，而是会在本地缓冲区中等待更多待发送的数据，这种批量发送数据的策略虽然会影响实时性和网络延迟，但是能够降低网络拥堵的可能性并减少额外开销。

在早期的互联网中，Telnet 是被广泛使用的应用程序，然而使用 Telnet 会产生大量只有 1 字节负载的有效数据，每个数据包都会有 40 字节的额外开销，带宽的利用率只有 ~2.44%，Nagle 算法就是在当时的这种场景下设计的。

当应用层协议通过 TCP 协议传输数据时，实际上待发送的数据先被写入了 TCP 协议的缓冲区，如果用户开启了 Nagle 算法，那么 TCP 协议可能不会立刻发送写入的数据，它会等待缓冲区中数据超过最大数据段（MSS）或者上一个数据段被 ACK 时才会发送缓冲区中的数据。
![nagle-algorithm](D:\Java\笔记\图片\1-11【网络编程】\format.png)

**图 2 - Nagle 算法**

Nagle 算法确实能够在数据包较小时提高网络带宽的利用率并减少 TCP 和 IP 协议头带来的额外开销，但是使用该算法也可能会导致应用层协议多次写入的数据被合并或者拆分发送，当接收方从 TCP 协议栈中读取数据时会发现不相关的数据出现在了同一个数据段中，应用层协议可能没有办法对它们进行拆分和重组。

除了 Nagle 算法之外，TCP 协议栈中还有另一个用于延迟发送数据的选项 `TCP_CORK`，如果我们开启该选项，那么当发送的数据小于 MSS 时，TCP 协议就会延迟 200ms 发送该数据或者等待缓冲区中的数据超过 MSS。

无论是 `TCP_NODELAY` 还是 `TCP_CORK`，它们都会通过延迟发送数据来提高带宽的利用率，它们会对应用层协议写入的数据进行拆分和重组，而这些机制和配置能够出现的最重要原因是 — TCP 协议是基于字节流的协议，其本身没有数据包的概念，不会按照数据包发送数据。

### 如何解决粘包

如果我们系统性地学习过 TCP 协议以及基于 TCP 的应用层协议设计，那么设计一个能够被 TCP 协议栈任意拆分和组装数据包的应用层协议就不会有什么问题。既然 TCP 协议是基于字节流的，这其实就意味着应用层协议要自己划分消息的边界。

如果我们能在应用层协议中定义消息的边界，那么无论 TCP 协议如何对应用层协议的数据包进程拆分和重组，接收方都能根据协议的规则恢复对应的消息。在应用层协议中，最常见的两种解决方案就是**基于长度或者基于终结符**（Delimiter）。

![message-framing](D:\Java\笔记\图片\1-11【网络编程】\format2.png)

**图 3 - 实现消息边界的方法**

基于长度的实现有两种方式，一种是使用固定长度，所有的应用层消息都使用统一的大小，另一种方式是使用不固定长度，但是需要在应用层协议的协议头中增加表示负载长度的字段，这样接收方才可以从字节流中分离出不同的消息，HTTP 协议的消息边界就是 **基于长度+负载长度** 实现的：

```xml
HTTP/1.1 200 OK
Content-Type: text/html; charset=UTF-8
Content-Length: 138
...
Connection: close
 
<html>
  <head>
    <title>An Example Page</title>
  </head>
  <body>
    <p>Hello World, this is a very simple HTML document.</p>
  </body>
</html>
```

在上述 HTTP 消息中，我们使用 `Content-Length` 头表示 HTTP 消息的负载大小，当应用层协议解析到足够的字节数后，就能从中分离出完整的 HTTP 消息，无论发送方如何处理对应的数据包，我们都可以遵循这一规则完成 HTTP 消息的重组。

虽然知道http-header中有`Content-Length,以为只是一个简单的标记左右,现在才知道是为了解决粘包问题.`

不过 HTTP 协议除了使用基于长度的方式实现边界，也会使用基于终结符的策略，当 HTTP 使用块传输（Chunked Transfer）机制时，HTTP 头中就不再包含 `Content-Length` 了，它会使用负载大小为 0 的 HTTP 消息作为终结符表示消息的边界。

还有在使用post进行表单上传文件时, 会有一个boundary字符串(大概张这样, --ZnGpDtePMx0KrHh_G0X99Yef9r8JZsRJSXC), 这个也是作为文件的一个分隔符, 也可以说是基于终结符策略的.

当然除了这两种方式之外，我们可以基于特定的规则实现消息的边界，例如：使用 TCP 协议发送 JSON 数据，接收方可以根据接收到的数据是否能够被解析成合法的 JSON 判断消息是否终结。

### 总结

TCP 协议粘包问题是因为应用层协议开发者的错误设计导致的，他们忽略了 TCP 协议数据传输的核心机制 — 基于字节流，其本身不包含消息、数据包等概念，所有数据的传输都是流式的，需要应用层协议自己设计消息的边界，即消息帧（Message Framing），我们重新回顾一下粘包问题出现的核心原因：

1. TCP 协议是基于字节流的传输层协议，其中不存在消息和数据包的概念；
2. 应用层协议可以使用基于长度或者基于终结符的消息边界，解决多个消息的粘连；

为什么会产生粘包和拆包呢？

- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；
- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；
- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；
- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 > MSS。

解决方案：

- 发送端将每个数据包封装为固定长度
- 在数据尾部增加特殊字符进行分割
- 将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小固定，且有一个字段声明内容体的大小。

## 6.8 KeepAlive

首先，我们要明确我们谈的是**TCP**的 **`KeepAlive`** 还是**HTTP**的 **`Keep-Alive`**。TCP的KeepAlive和HTTP的Keep-Alive**是完全不同的概念，不能混为一谈**。

实际上HTTP的KeepAlive写法是`Keep-Alive`，跟TCP的`KeepAlive`写法上也有不同。

- TCP的**keepalive**是侧重在保持客户端和服务端的连接，一方会不定期发送心跳包给另一方，当一方端掉的时候，没有断掉的定时发送几次**心跳包**，如果间隔发送几次，对方都返回的是RST，而不是ACK，那么就释放当前链接。

  设想一下，如果tcp层没有keepalive的机制，一旦一方断开连接却没有发送FIN给另外一方的话，那么另外一方会一直以为这个连接还是存活的，几天，几月。那么这对服务器资源的影响是很大的。

- HTTP的**keep-alive**一般我们都会带上中间的**横杠**，普通的http连接是客户端连接上服务端，然后结束请求后，由客户端或者服务端进行http连接的关闭。下次再发送请求的时候，客户端再发起一个连接，传送数据，关闭连接。这么个流程反复。

  但是一旦客户端发送`connection:keep-alive`头给服务端，且服务端也接受这个keep-alive的话，两边对上暗号，这个连接就可以复用了，一个http处理完之后，另外一个http数据直接从这个连接走了。减少新建和断开TCP连接的消耗。

二者的作用简单来说：

> HTTP协议的Keep-Alive意图在于短时间内连接复用，希望可以短时间内在同一个连接上进行多次请求/响应。
>
> TCP的KeepAlive机制意图在于保活、心跳，检测连接错误。当一个TCP连接两端长时间没有数据传输时(通常默认配置是2小时)，发送keepalive探针，探测链接是否存活。

**总之，记住HTTP的Keep-Alive和TCP的KeepAlive不是一回事。**

**tcp的keepalive是在ESTABLISH状态的时候，双方如何检测连接的可用行。**

**而http的keep-alive说的是如何避免进行重复的TCP三次握手和四次挥手的环节。**

### TCP的KeepAlive

**为什么要有KeepAlive**

在谈KeepAlive之前，我们先来了解下简单TCP知识。首先要明确的是在TCP层是没有“请求”一说的，经常听到在TCP层发送一个请求，这种说法是错误的。

TCP是一种通信的方式，“请求”一词是事务上的概念，HTTP协议是一种事务协议，如果说发送一个HTTP请求，这种说法就没有问题。也经常听到面试官反馈有些面试运维的同学，基本的TCP三次握手的概念不清楚，面试官问TCP是如何建立链接，面试者上来就说，假如我是客户端我发送一个请求给服务端，服务端发送一个请求给我。。。

这种一听就知道对TCP基本概念不清楚。下面是通过wireshark抓取的一个TCP建立握手的过程。（命令行基本上用TCPdump,后面我们还会用这张图说明问题）:

![](D:\Java\笔记\图片\1-11【网络编程】\13.jpg)

现在只要看前3行，这就是TCP三次握手的完整建立过程，第一个报文SYN从发起方发出，第二个报文SYN,ACK是从被连接方发出，第三个报文ACK确认对方的SYN，ACK已经收到，如下图：

![](D:\Java\笔记\图片\1-11【网络编程】\14.webp)

但是数据实际上并没有传输，请求是有数据的，第四个报文才是数据传输开始的过程，wireshark把第四个报文解析成HTTP协议，HTTP协议的GET方法和URI也解析出来，所以说TCP层是没有请求的概念，HTTP协议是事务性协议才有请求的概念，TCP报文承载HTTP协议的请求(Request)和响应(Response)。

现在才是开始说明为什么要有KeepAlive。链接建立之后，如果应用程序或者上层协议一直不发送数据，或者隔很长时间才发送一次数据，当链接很久没有数据报文传输时如何去确定对方还在线，到底是掉线了还是确实没有数据传输，链接还需不需要保持，这种情况在TCP协议设计中是需要考虑到的。

TCP协议通过一种巧妙的方式去解决这个问题，当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明对方还在线，链接可以继续保持，如果对方没有报文返回，并且重试了多次之后则认为链接丢失，没有必要保持链接。

**怎么开启KeepAlive？**

KeepAlive并不是默认开启的，在Linux系统上没有一个全局的选项去开启TCP的KeepAlive。需要开启KeepAlive的应用必须在TCP的socket中单独开启。Linux Kernel有三个选项影响到KeepAlive的行为：

> - tcp_keepalive_time 7200// 距离上次传送数据多少时间未收到新报文判断为开始检测，单位秒，默认7200s
> - tcp_keepalive_intvl 75// 检测开始每多少时间发送心跳包，单位秒，默认75s
> - tcp_keepalive_probes 9// 发送几次心跳包对方未响应则close连接，默认9次

TCP socket也有三个选项和内核对应，通过setsockopt系统调用针对单独的socket进行设置：

> - TCPKEEPCNT: 覆盖 tcpkeepaliveprobes
> - TCPKEEPIDLE: 覆盖 tcpkeepalivetime
> - TCPKEEPINTVL: 覆盖 tcpkeepalive_intvl

举个例子，以我的系统默认设置为例，kernel默认设置的tcpkeepalivetime是7200s, 如果我在应用程序中针对socket开启了KeepAlive,然后设置的TCP_KEEPIDLE为60，那么TCP协议栈在发现TCP链接空闲了60s没有数据传输的时候就会发送第一个探测报文。

**KeepAlive的不足和局限性**

其实，tcp自带的keepalive还是有些不足之处的。

keepalive只能检测连接是否存活，不能检测连接是否可用。例如，某一方发生了死锁，无法在连接上进行任何读写操作，但是操作系统仍然可以响应网络层keepalive包。

TCP keepalive 机制依赖于操作系统的实现,灵活性不够，默认关闭，且默认的 keepalive 心跳时间是 两个小时, 时间较长。代理(如socks proxy)、或者负载均衡器，会让tcp KeepAlive失效

### HTTP的Keep-Alive

通常一个网页可能会有很多组成部分，除了文本内容，还会有诸如：js、css、图片等静态资源，有时还会异步发起AJAX请求。只有所有的资源都加载完毕后，我们看到网页完整的内容。然而，一个网页中，可能引入了几十个js、css文件，上百张图片，如果每请求一个资源，就创建一个连接，然后关闭，代价实在太大了。

基于此背景，我们希望连接能够在短时间内得到复用，在加载同一个网页中的内容时，尽量的复用连接，这就是HTTP协议中keep-alive属性的作用。

> - HTTP的Keep-Alive是**HTTP1.1**中**默认开启**的功能。通过headers设置"`Connection: close` "关闭
> - 在HTTP1.0中是**默认关闭**的。通过headers设置"`Connection: Keep-Alive`"开启。

对于客户端来说，不论是浏览器，还是手机App，或者我们直接在Java代码中使用`HttpUrlConnection`，只是负责在请求头中设置Keep-Alive。Keep-Alive属性保持连接的**时间长短是由服务端决定的**，通常配置都是在**几十秒左右。**

开启HTTP Keep-Alive之后，能复用已有的TCP链接，当前一个请求已经响应完毕，服务器端没有立即关闭TCP链接，而是等待一段时间接收浏览器端可能发送过来的第二个请求，通常浏览器在第一个请求返回之后会立即发送第二个请求，如果某一时刻只能有一个链接，同一个TCP链接处理的请求越多，开启KeepAlive能节省的TCP建立和关闭的消耗就越多。

当然通常会启用多个链接去从服务器器上请求资源，但是开启了Keep-Alive之后，仍然能加快资源的加载速度。HTTP/1.1之后默认开启Keep-Alive, 在HTTP的头域中增加Connection选项。当设置为`Connection:keep-alive`表示开启，设置为`Connection:close`表示关闭。
