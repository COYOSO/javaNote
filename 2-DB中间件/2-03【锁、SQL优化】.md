# 第一章 MySQL锁机制

<!-- 共享读锁、排他写锁 -->

锁是计算机用以协调多个进程间并发访问同一共享资源的一种机制。MySQL中为了保证数据访问的一致性与有效性等功能，实现了锁机制，MySQL中的锁是在服务器层或者存储引擎层实现的。

锁是用来解决并发事务的访问问题，我们已经知道事务并发执行时可能带来的各种问题，最大的一个难点是：一方面要最大程度地利用数据库的并发访问，另外一方面还要确保每个用户能以一致的方式读取和修改数据，尤其是一个事务进行读取操作，另一个同时进行改动操作的情况下。

一个事务进行读取操作，另一个进行改动操作，这种情况下可能发生脏读、不可重复读、幻读的问题。有两种可选的解决方案：

* 方案一：读操作MVCC，写操作进行加锁。该方案性能较好，但可能会读到旧版本记录
* 方案二：读写操作都加锁。该方案性能一般，但是每次都可以读取到最新的记录，比如在银行场景中，对安全性要求非常高。

MySQL中的锁，可以根据模式、粒度、属性、状态、算法来进行分类：

* 模式分类：乐观锁、悲观锁。
* 粒度分类：全局锁、表级锁、行级锁。
* 属性分类：共享锁（又称为读锁，简称为S锁）、排他锁（又称为写锁和独占锁，简称为X锁）。
* 状态分类：意向共享锁、意向排他锁。
* 算法分类：间隙锁、临键锁、记录锁。

## 1.1 乐观锁和悲观锁

这两个锁并不存在，都是抽象的概念，需要我们自己去事项。乐观锁和悲观锁都是针对读（select）来说的。

**乐观锁**

乐观锁，就是非常乐观。乐观锁认为数据一般情况下不会造成冲突，在操作数据时不加锁，在进行更新后再去判断是否有冲突。乐观锁适用于读操作多，写操作少的场景。

乐观锁是基本版本号机制实现的，数据表中增加一个 version 字段，读取数据时将 version 一起读出。数据每更新一次，version 字段值 + 1。当修改需要提交时，将读取时的版本号与数据库当前版本号做比较，如果一致，说明在此期间无人修改这条记录，不一致则说明已经被修改了，提交失败。

**悲观锁**

悲观锁是相比较乐观锁而言的，就是比较悲观，悲观锁认为数据每次操作都会被修改，所以在每次操作数据时都会加上锁。

悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。MySQL中的悲观锁由共享锁或者排他锁实现，共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。

## 1.2 全局锁

全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DDL语句（建表、修改表结构等）、DML语句（数据的增删改）和已经更新操作的事务提交语句都将被阻塞。

其典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性。

```sql
-- 加上全局读锁，让整个库处于只读状态。这种方式叫做FTWRL（flush tables with read lock）
flush tables with read lock;
-- 数据备份，在shell窗口就可以 linxuan是数据库名称
mysqldump -u root –p 1234 linxuan > D:/linxuan.sql
-- 释放锁
unlock tables;
```

数据库中加全局锁，是一个比较重的操作，存在以下问题：

- 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。 
- 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。

可以通过只开启一个事务拿到一致性视图。在InnoDB引擎中，在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。我们可以在备份时加上参数 `--single-transaction` （开启单个事务）参数来完成不加锁的一致性数据备份。

除了FTWRL可以让整个库处于只读状态，还有一种方式`set global readonly = true`，但是这种方式并不推荐：

1. 在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，不建议使用。

2. 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。

## 1.3 表级锁

表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。

对于表级锁，主要分为以下四类： 表锁、元数据锁（meta data lock，MDL） 、意向锁、AUTO-INC 锁。

### 1.3.1 表锁

对于表锁，分为两类： 表共享读锁、表排他写锁。

```sql
-- 语法如下
-- 加锁，表共享锁或者表独占锁 lock tables student read;
lock tables 表名... read/write;
-- 释放锁，会释放当前会话的所有表锁。如果不释放当前锁，关闭本次会话连接也会释放锁。
unlock tables;
```

读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写。

- 表共享锁： 读锁不会阻塞其他客户端的读，但是会阻塞本客户端以及其他客户端的写。
- 表排他锁：写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写。


尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能。

### 1.3.2 元数据锁

元数据锁（meta data lock，MDL）：MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做变更。MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。

- 对一张表进行 CRUD 操作时，加的是 MDL 共享读锁；读锁和读锁不会冲突。
- 对一张表做结构变更操作的时候，加的是 MDL 排他写锁；读锁和写锁会冲突。

当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。

当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。

```sql
-- 使用performance_schema数据库。它提供底层监控功能，主要用于收集数据库服务器性能参数。
mysql> use performance_schema;
Database changed

-- 查看这个performance_schema数据库中metadata_locks表信息，也就是查看MDL信息。
mysql> select object_type, object_schema, object_name, lock_type, lock_duration from performance_schema.metadata_locks;
+-------------+--------------------+----------------+-------------+---------------+
| object_type | object_schema      | object_name    | lock_type   | lock_duration |
+-------------+--------------------+----------------+-------------+---------------+
| TABLE       | performance_schema | metadata_locks | SHARED_READ | TRANSACTION   |
+-------------+--------------------+----------------+-------------+---------------+
1 row in set (0.00 sec)
```

MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：

- 线程 A 启用了事务（但是一直不提交），然后执行一条 select 语句，此时先对该表加上 MDL 读锁；
- 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；
- 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞。

那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。

线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞。这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。

### 1.3.3 意向锁

意向锁的目的是为了快速判断表里是否有记录被加锁。为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。

假如没有意向锁，客户端一开启一个事务，然后执行DML操作，在执行DML语句时，会对涉及到的行加行锁。当客户端二想对这张表加表锁时，会检查当前表是否有对应的行锁，如果没有，则添加表锁，此时就会从第一行数据，检查到最后一行数据，效率较低。

<img src="..\图片\2-03【锁、SQL优化】\1-1意向锁.png" />

有了意向锁之后，客户端一在执行DML操作时，会对涉及的行加行锁，同时也会对该表加上意向锁。而其他客户端，在对这张表加表锁的时候，会根据该表上所加的意向锁来判定是否可以成功加表锁，而不用逐行判断行锁情况了。

- 意向共享锁（Intention Share，简称IS）：在使用 InnoDB 引擎的表里对某些数据加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 意向排他锁（Intention Exclusive 简称IX）：在使用 InnoDB 引擎的表里对某些数据加上「排他锁」之前，需要先在表级别加上一个「意向排他锁」；也就是当执行插入、更新、删除操作，需要先对表加上「意向排他锁」，然后对该记录加排他锁。

意向共享锁和意向排他锁是表级锁，不会和行级的共享锁和排他锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables ... read）和排他表锁（lock tables ... write）发生冲突。读读共享、读写互斥、写写互斥

一旦事务提交了，意向共享锁、意向排他锁，都会自动释放。

```sql
-- 查看意向锁及行锁的加锁情况
mysql> select object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;
Empty set (0.01 sec)
```

首先开启两个客户端。

```sql
-- 客户端1打开事务，并添加意向共享锁
mysql>  begin;
-- 添加了一个行级共享锁，在此之前会添加表级意向共享锁。
mysql>  select * from student where id  = 1 lock in share mode;
+----+--------+------------+
| id | name   | no         |
+----+--------+------------+
|  1 | 黛绮丝 | 2000100102 |
+----+--------+------------+
1 row in set (0.00 sec)
```

这个时候就能够在客户端2查看意向共享锁的情况了：

```sql
-- 客户端2
mysql>  select object_schema, object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;
+-------------+------------+-----------+---------------+-----------+ -- lock_type：锁的类型
| object_name | index_name | lock_type | lock_mode     | lock_data | -- lock_mode：锁的方式
+-------------+------------+-----------+---------------+-----------+ -- TABLE：表锁
| student     | NULL       | TABLE     | IS            | NULL      | -- IS：意向共享锁
| student     | PRIMARY    | RECORD    | S,REC_NOT_GAP | 1         | -- RECORD：行锁
+-------------+------------+-----------+---------------+-----------+ -- S：共享锁
2 rows in set (0.00 sec)                                             -- REC_NOT_GAP：行锁
```

而这个时候在客户端2为表加共享读锁是没有任何问题的，但是加上表排他写锁就有问题了，就会被阻塞。

```sql
-- 添加一个表共享读锁，表共享读锁与表排他写锁冲突，与意向共享锁没有任何问题。
mysql> lock tables student read;
Query OK, 0 rows affected (0.00 sec)

-- 添加表排他写锁，与意向共享锁冲突，发生阻塞状态。
mysql> lock tables student write;
```

### 1.3.4 AUTO-INC/轻量级锁

在为某个字段声明 `AUTO_INCREMENT` 属性时，之后可以在插入数据时，可以不指定该字段的值，数据库会自动给该字段赋值递增的值，这主要是通过 AUTO-INC 锁实现的。

AUTO-INC 锁是特殊的表锁机制，它不是在一个事务提交后才释放，而是在执行完插入语句后就会立即释放。在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为 `AUTO_INCREMENT` 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。

一个事务在持有 AUTO-INC 锁的过程中，其他事务如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 `AUTO_INCREMENT` 修饰的字段的值是连续递增的。但是， 这样的话会导致AUTO-INC 锁在对大量数据进行插入的时候，会影响插入性能。

因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种轻量级的锁来实现自增。一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上`轻量级锁`，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。

InnoDB 存储引擎提供了个 `innodb_autoinc_lock_mode` 的系统变量，用来控制选择哪一种锁。

```sql
mysql> select @@innodb_autoinc_lock_mode;
+----------------------------+
| @@innodb_autoinc_lock_mode | -- 值为0，采用 AUTO-INC 锁
+----------------------------+ -- 值为2，采用轻量级锁
|                          2 | -- 值为1，两种锁混着用，能够确定插入数据的数量就采用轻量级锁，
+----------------------------+ --                    不确定时就采用 AUTO-INC 锁。 
1 row in set (0.00 sec)
```

当 `innodb_autoinc_lock_mode = 2` 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，这在有主从复制的场景中是不安全的。

## 1.4 行级锁

行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。MySQL 中只有 InnoDB 引擎支持行锁，其他不支持。InnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。

对于行级锁，主要分为以下三类：

- 记录锁（Record Lock，又叫做行锁）：仅仅把一条记录锁上，防止其他事务对此行进行update和delete。在RC(`read committed`)、RR(`repeatable read`)隔离级别下都支持。
- 间隙锁（Gap Lock）：锁定一个范围，但是不包含记录本身。确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR(`repeatable read`)隔离级别下支持。
- 临键锁（Next-Key Lock）Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。在RR(`repeatable read`)隔离级别下支持。

默认情况下，InnoDB 在RR(`repeatable read`)事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。

- 针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。
- InnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，此时 就会升级为表锁。
- 索引上的等值查询(唯一索引)，给不存在的记录加锁时，优化为间隙锁 。 
- 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。
- 索引上的范围查询(唯一索引)--会访问到不满足条件的第一个值为止。

### 1.4.1 记录/行锁Record Lock

<img src="..\图片\2-03【锁、SQL优化】\1-2行锁.png" />

InnoDB实现了以下两种类型的行锁：

- 共享锁（读锁，简称S锁）：多个事务都可以加共享锁读同⼀⾏数据，但是别的事务不能写这⾏数据。
  一个事务获取了共享锁，其他事务也只能加共享锁或不加锁查询。其他事务不能写。其他事务加排他锁查不到，因为排他锁与共享锁不能存在同一数据上。  
- 排他锁（写锁，简称X锁）：⼀个事务可以读/写这⾏数据，别的事务只能读不能写。
  一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁。获取排他锁的事务可以对数据就行读取和修改。其他事务可以通过`select ...from...`查询数据，因为普通查询没有任何锁机制。其他事务不能写。

两种行锁的兼容情况如下：读读共享、读写互斥、写写互斥。

```sql
-- InnoDB引擎默认的修改update、delete、insert语句，都会自动给涉及到的数据加上排他锁，select语句不会加任何锁
-- 加行共享锁
select ... lock in share mode
-- 加行排他锁
select ...for update
```

常见的SQL语句，在执行时，所加的行锁如下：

| SQL                           | 行锁类型   | 说明                                     |
| ----------------------------- | ---------- | ---------------------------------------- |
| INSERT / UPDATE / DELETE      | 排他锁     | 自动加锁                                 |
| SELECT（正常）                | 不加任何锁 |                                          |
| SELECT ... LOCK IN SHARE MODE | 共享锁     | 需要手动在SELECT之后加LOCK IN SHARE MODE |
| SELECT ... FOR UPDATE         | 排他锁     | 需要手动在SELECT之后加FOR UPDATE         |

```sql
-- 创建一个 记录/行排他锁。它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行。
select * from account where id = 1 for update;
```

下面演示一下行排他锁冲突的情况：

<img src="..\图片\2-03【锁、SQL优化】\1-3演示排他锁冲突.png" />

```sql
-- 客户端A操作如下：
-- 开启事务
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

-- 查询账户表
mysql> select * from account;
+----+--------+---------+
| id | name   | balance |
+----+--------+---------+
|  1 | lilei  |     350 |
|  2 | hanmei |   16000 |
+----+--------+---------+
2 rows in set (0.00 sec)

-- 为记录为1的索引加上记录/行排他锁，阻止其他事务插入、更新、删除这一行。
mysql> select * from account where id = 1 for update;
+----+-------+---------+
| id | name  | balance |
+----+-------+---------+
|  1 | lilei |     350 |
+----+-------+---------+
1 row in set (0.00 sec)
```

```sql
-- 客户端B操作如下：
-- 开启事务
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

-- 查询该表加锁信息
mysql> select object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;
+-------------+------------+-----------+---------------+-----------+ -- TABLE.IX：表意向排他锁。
| object_name | index_name | lock_type | lock_mode     | lock_data | --           加行排他锁之前加该锁
+-------------+------------+-----------+---------------+-----------+ --           之后可根据意向锁判断
| account     | NULL       | TABLE     | IX            | NULL      |
| account     | PRIMARY    | RECORD    | X,REC_NOT_GAP | 1         | -- RECORD.X：行排他锁
+-------------+------------+-----------+---------------+-----------+ -- REC_NOT_GAP：行锁
2 rows in set (0.00 sec)

-- 更新id为2的记录，不受影响
mysql> update account set balance = 10000 where id = 2;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

-- 更新id为1的记录，更新失败。
-- 更新操作会添加排他锁，写写锁之间互斥。
mysql> update account set balance = 10000 where id = 1;
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
```

### 1.4.2 间隙锁Gap Lock

间隙锁（Gap Lock）：锁定一个范围，但是不包含记录本身。确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。间隙锁基于非唯一索引，它锁定一段范围内的索引记录。使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。

间隙锁的目的是为了防止幻读（其他事务插入间隙），其主要通过两个方面实现这个目的：

- 防止间隙内有新数据被插入。
- 防止已存在的数据，更新成间隙内的数据。

innodb自动使用间隙锁的条件：

- 必须在RR级别下
- 检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加）

间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。

<img src="..\图片\2-03【锁、SQL优化】\1-4间隙锁.png" />

```sql
-- id是主键索引，num添加了索引
mysql> select * from tb_num;
+----+------+
| id | num  |
+----+------+
|  1 |    2 |
|  3 |    4 |
|  6 |    5 |
|  8 |    5 |
| 10 |    5 |
| 13 |   11 |
+----+------+
6 rows in set (0.00 sec)

-- 添加的间隙锁在（num = 2， num = 4）和（num = 4， num = 5）中间。
select * from tb_num where num = 4 for update;
-- num的值并没有13，所以添加的间隙锁在（11， +∞），记录(id = 13, num = 11)之后不能再插入记录
select * from tb_num where num = 13 for update;
-- 间隙锁锁住的位置有：（4， 5）（5， 5）（5， 11）中间。在这个中间是不能够插入进去数据的。插入（id=9，num=12）是没有任何问题的，因为并没有锁住12的位置。插入（id=12， num=10）会出问题。
select * from tb_num where num = 5 for update;
-- 从4到正无穷都被间隙锁给锁住了。执行该语句update tb_num set id=4 where num=4会报错，插入的区域被锁定了
select * from tb_num where num > 4 for update;
```

演示一下：

```sql
-- 客户端A开启事务
-- 查看表信息
mysql> select * from tb_num;
+----+------+
| id | num  |
+----+------+
|  1 |    2 |
|  3 |    4 |
|  6 |    5 |
|  8 |    5 |
| 10 |    5 |
| 13 |   11 |
+----+------+
6 rows in set (0.00 sec)

-- 为num字段创建索引，创建了一个二级索引，间隙锁针对非唯一二级索引。
mysql> create index idx_num on tb_num(num);
Query OK, 0 rows affected (0.03 sec)
Records: 0  Duplicates: 0  Warnings: 0

-- 显示该表所有索引
mysql> show index from tb_num;
+--------+------------+----------+--------------+-------------+-----------+-------------+
| Table  | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality |
+--------+------------+----------+--------------+-------------+-----------+-------------+
| tb_num |          0 | PRIMARY  |            1 | id          | A         |           6 |
| tb_num |          1 | idx_num  |            1 | num         | A         |           4 |
+--------+------------+----------+--------------+-------------+-----------+-------------+
2 rows in set (0.00 sec)

-- 开启事务
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

-- 因为有索引，所以这里不仅仅会加上记录锁，更会加上间隙锁。
-- 添加的间隙锁是在这一行数据和其他相邻两行数据的中间，所以这中间不能够添加，其他地方能够添加
mysql> select * from tb_num where num = 4 for update;
+----+------+
| id | num  |
+----+------+
|  3 |    4 |
+----+------+
1 row in set (0.00 sec)
```

```sql
-- 客户端B操作
-- 开启事务
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

-- 查看锁信息
mysql> select object_name, index_name, lock_type, lock_mode, lock_data from performance_schema.data_locks;
+-------------+------------+-----------+---------------+-----------+
| object_name | index_name | lock_type | lock_mode     | lock_data |
+-------------+------------+-----------+---------------+-----------+
| tb_num      | NULL       | TABLE     | IX            | NULL      | -- 表意向排他锁，行排他锁添加前添加
| tb_num      | PRIMARY    | RECORD    | X,GAP         | 3         | -- 唯一索引 行 间隙锁
| tb_num      | idx_num    | RECORD    | X             | 4, 3      | -- idx_num 行 排他锁
| tb_num      | PRIMARY    | RECORD    | X,REC_NOT_GAP | 3         | -- 唯一索引 行 记录/行锁
| tb_num      | idx_num    | RECORD    | X,GAP         | 5, 6      | -- idx_num 行 间隙锁
+-------------+------------+-----------+---------------+-----------+
6 rows in set (0.00 sec)

-- 在间隙锁的范围内添加数据，肯定失败。
mysql> insert into tb_num value(2, 4);
ERROR 1317 (70100): Query execution was interrupted

-- 这个范围内没有间隙锁，添加成功。
mysql> insert into tb_num value(7, 5);
Query OK, 1 row affected (0.00 sec)
```

### 1.4.3 临键锁Next-Key Lock

next-key锁包含了记录锁和间隙锁，即锁定一个范围，并且锁定记录本身，InnoDB默认加锁方式是next-key 锁。

<img src="..\图片\2-03【锁、SQL优化】\1-5临键锁.png" />

每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。

# 第二章 SQL优化

<!-- explain 解释，说明，阐明 -->

```sql
# 创建一个表tb_user，查看表中字段
CREATE TABLE tb_user(
    id INT PRIMARY KEY AUTO_INCREMENT,
    NAME VARCHAR(50) NOT NULL,
    phone VARCHAR(11) NOT NULL,
    email VARCHAR(100),
    profession VARCHAR(11),
    age TINYINT UNSIGNED,
    gender CHAR(1),
    STATUS CHAR(1),
    createtime DATETIME
);

-- 查看表中数据
mysql> select * from tb_user;
+----+------+-------+-------+------------+------+--------+--------+------------+
| id | name | phone | email | profession | age  | gender | status | createtime |
+----+------+-------+-------+------------+------+--------+--------+------------+
|  1 | 张三 | 123   | 123   | 小偷       |   20 | 男     | 1      | NULL       |
|  2 | 李四 | 124   | 124   | 强盗       |   21 | 男     | 0      | NULL       |
|  3 | 王五 | 125   | 125   | 骗子       |   22 | 女     | 0      | NULL       |
+----+------+-------+-------+------------+------+--------+--------+------------+
3 rows in set (0.00 sec)

# 创建联合索引
create index idx_user_pro_age_sta on tb_user(profession, age, status);
# 创建前缀索引
create index idx_user_email_5 on tb_user(email(5));
# 显示索引
show index from tb_user;
+---------+------------+----------------------+--------------+-------------+
| Table   | Non_unique | Key_name             | Seq_in_index | Column_name |
+---------+------------+----------------------+--------------+-------------+
| tb_user |          0 | PRIMARY              |            1 | id          |
| tb_user |          1 | idx_user_pro_age_sta |            1 | profession  |
| tb_user |          1 | idx_user_pro_age_sta |            2 | age         |
| tb_user |          1 | idx_user_pro_age_sta |            3 | status      |
| tb_user |          1 | idx_user_email_5     |            1 | email       |
+---------+------------+----------------------+--------------+-------------+
```

## 2.1 性能分析

MySQL中性能分析的方式有：

* 查看当前数据库中语句执行频次：判断数据库以增删改查中哪一项为主，从而进行优化
* 开启慢查询日志：SQL语句执行时间超过慢查询规定的时间，那么就会被记录下来信息，方便分析。
* 开启profile文件：可以查看SQL语句的各个阶段的耗时时间。
* 查看SQL语句执行详细信息：通过explain或者desc查看当前SQL语句执行的详细信息。

**查看执行频次**

MySQL 客户端连接成功后，通过 `show [session | global] status` 命令可以提供服务器状态信息。我们可以通过指令查看到当前数据库到底是以查询为主，还是以增删改为主，从而为数据库优化提供参考依据。

* 如果是以增删改为主，我们可以考虑不对其进行索引的优化。
* 如果是以查询为主，那么就要考虑对数据库的索引进行优化了。

```sql
-- session 是查看当前会话、global 是查询全局数据 ;
-- 一共有7个下划线，小写的com_______也可以
SHOW GLOBAL STATUS LIKE 'Com_______';		
```

**慢查询日志**

慢查询日志记录了所有执行时间超过指定参数`long_query_time`的所有SQL语句的日志。

```sql
# 查看慢查询日志开关状态
mysql> select @@slow_query_log;

# 开启慢查询日志开关，MySQL8中默认已经开启了。之后就可以在/var/lib/mysql/localhost-slow.log查看慢的语句了。
mysql> set global slow_query_log = 1;
Query OK, 0 rows affected (0.00 sec)

# 设置慢查询日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询日志。默认10秒。
mysql> set long_query_time = 2;
Query OK, 0 rows affected (0.00 sec)
```

**profile文件**

`show profiles` 能在做SQL优化时帮我们了解时间都耗费在哪里。

```sql
-- 查看当前MySQL是否支持 profile 操作，结果为YES代表支持，但是支持不一定代表开启这个功能，需要我们手动开启
mysql> SELECT @@have_profiling;
+------------------+
| @@have_profiling |
+------------------+
| YES              |
+------------------+
1 row in set, 1 warning (0.00 sec)

-- 查看该项功能是否开启，发现并没有开启。
mysql> select @@profiling;
+-------------+
| @@profiling |
+-------------+
|           0 |
+-------------+
1 row in set, 1 warning (0.00 sec)

-- 开启profiling功能，这样可以查看语句的耗时。MySQL8默认没有开启。
SET profiling = 1;

-- 查看所有语句的耗时
show profiles;
-- 查看指定query_id的SQL语句各个阶段的耗时
show profile for query query_id;
-- 查看指定query_id的SQL语句CPU的使用情况
show profile cpu for query query_id;
```

**explain**

EXPLAIN或者DESC命令获取执行SELECT语句的信息，包括SELECT语句执行过程中表如何连接和连接的顺序。

```sql
-- 直接在select语句之前加上关键字 explain / desc
EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件 ;

-- 获取执行该语句的信息
mysql> explain select * from tb_user;
+----+-------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | ALL  | NULL          | NULL | NULL    | NULL |    1 |   100.00 | NULL  |
+----+-------------+------+---------------+------+---------+------+------+----------+-------+
```

<img src="..\图片\2-03【锁、SQL优化】\2-1获取SQL语句信息.png" />

Explain 执行计划中各个字段的含义：

- `id`：select 查询的序列号，表示查询中执行 select 子句或者操作表的顺序（id相同，执行顺序从上到下；id不同，值越大越先执行）
- `select_type`：表示 SELECT 的类型，常见取值有 SIMPLE（简单表，即不适用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE之后包含子查询）等
- `type`：表示连接类型，性能由好到差的连接类型为 NULL、system、const、eq_ref、ref、range、index、all，尽量将性能提升到const就可以了。
- `possible_key`：可能应用在这张表上的索引，一个或多个
- `Key`：实际使用的索引，如果为 NULL，则没有使用索引
- `Key_len`：表示索引中使用的字节数，该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好
- `rows`：MySQL认为必须要执行的行数，在InnoDB引擎的表中，是一个估计值，可能并不总是准确的
- `filtered`：表示返回结果的行数占需读取行数的百分比，filtered的值越大越好。

## 2.2 新增数据优化

如果需要一次性往数据库表中插入多条记录，可以从以下三个方面进行优化：批量插入数据、开启事务插入数据、主键顺序插入数据。

```sql
-- 批量插入数据
-- 这种方式建议插入1000条数据之内，如果超过了可以使用多条insert语句
Insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry');

-- 手动开启事务插入数据
start transaction;
insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry');
commit;

-- 主键顺序插入数据。主键顺序插入，性能要高于乱序插入。
主键乱序插入 : 8 1 9 21 88 2 4 15 89 5 7 3
主键顺序插入 : 1 2 3 4 5 7 8 9 15 21 88 89
```

如果一次性需要插入大批量数据（比如几百万的记录），使用insert语句插入性能较低，此时可以使用MySQL数据库提供的load指令进行插入（主键顺序插入性能高于乱序插入）。操作如下：

```sql
-- 客户端连接服务端时，加上参数 -–local-infile
mysql –-local-infile -u root -p

-- 查看从本地加载文件导入数据的开关是否打开，0为关闭，1为打开
select @@local_infile;

-- 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关
set global local_infile = 1;

-- 执行load指令将准备好的数据，加载到tb_user表结构中
-- 第一个‘,’的意思是每行数据每个字段之间的分隔符，‘\n’的意思是每行数据的分隔符
load data local infile '/usr/local/mysql/sql/load_user_100w_sort.sql' into table tb_user fields terminated by ',' lines terminated by '\n' ;
```

## 2.3 主键设计原则

主键设计原则如下：

* 满足业务需求的情况下，尽量降低主键的长度。 在InnoDB引擎中，索引分为聚集索引和二级索引。聚集索引只有一个，而二级索引有多个，二级索引的叶子节点中存储的就是主键。如果主键长度比较长，加上二级索引比较多，那么会占用大量的磁盘空间。搜索的时候也会耗费大量的磁盘IO。

* 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键。

* 尽量不要使用UUID做主键或者是其他自然主键，如身份证号。 

* 业务操作时，避免对主键的修改。

主键顺序插入的性能是要高于乱序插入的， 下面介绍一下具体的原因。在InnoDB存储引擎中，表数据都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表IOT (index organized table IOT)。

<img src="..\图片\2-03【锁、SQL优化】\2-2主键设计原则.png" />

行数据，都是存储在聚集索引的叶子节点上的。在InnoDB引擎中，数据行是记录在逻辑结构 page 页中的，而每一个页的大小是固定的，默认16K。那也就意味着， 一个页中所存储的行也是有限的，如果插入的数据行row在该页存储比较大，那么将会存储到下一个页中，页与页之间会通过指针连接。

### 2.3.1 页分裂

页可以为空，也可以填充一半，也可以填充100%。如果是主键顺序插入，那么不会有任何问题。从磁盘中申请页，主键顺序插入，当第一页写满之后，再写入第二个页，页与页之间会通过指针连接，之后再写入第三页。

<img src="..\图片\2-03【锁、SQL优化】\2-3页分裂.png" />

但是主键乱序插入效果就不一样了。假如`1#`,`2#`页都已经写满了，存放了如图所示的数据

<img src="..\图片\2-03【锁、SQL优化】\2-4页分裂.png" />

此时再插入id为50的记录，按照顺序，应该存储在47之后。但是47所在的`1#`页，已经写满了，存储不了50对应的数据了。 那么此时会开辟一个新的页 `3#`，但是并不会直接将50存入`3#`页，而是会将`1#`页后一半的数据，移动到`3#`页，然后在`3#`页，插入50。

<img src="..\图片\2-03【锁、SQL优化】\2-5页分裂.png" />

那么此时，这三个页之间的数据顺序是有问题的。所以需要重新设置链表指针。

<img src="..\图片\2-03【锁、SQL优化】\2-6页分裂.png" />

上述的这种现象，称之为 "页分裂"，是比较耗费性能的操作。

### 2.3.2 页合并

目前表中已有数据的索引结构(叶子节点)如下：

<img src="..\图片\2-03【锁、SQL优化】\2-7页合并.png" />

当我们对已有数据进行删除时，实际上记录并没有被物理删除，只是记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。

<img src="..\图片\2-03【锁、SQL优化】\2-8页合并.png" />

当页中删除的记录达到 `MERGE_THRESHOLD`（合并页的阈值，默认为页的50%），InnoDB会开始寻找最靠近的页（前 或后）看看是否可以将两个页合并以优化空间使用。

<img src="..\图片\2-03【锁、SQL优化】\2-9页合并.png" />

删除数据，并将页合并之后，再次插入新的数据21，则直接插入`3#`页。这个里面所发生的合并页的这个现象，就称之为 "页合并"。

## 2.4 order by排序优化

MySQL的排序，有两种方式：`Using filesort`和`Using index`。

- `Using filesort`：通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区sort buffer 中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序。 
- `Using index`：通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高。优化排序操作时，尽量要优化为 Using index。

order by优化原则：

- 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则。
- 尽量使用覆盖索引，这样就不用再进行回表查询。
- 多字段排序, 一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC/DESC）。 
- 如果不可避免的出现filesort，大数据量排序时，可以增大排序缓冲区大小 `sort_buffer_size`(默认256k)。

**根据排序字段建立合适的索引**

```sql
-- 按照age升序排序，查看id、age、phone字段。
-- 虽然idx_user_pro_age_sta索引里面有该字段，但是根据最左前缀法则，该索引会失效。所以使用filesort排序方式
explain select id, age, phone from tb_user order by age ;
+----+-------------+---------+------+---------------+------+----------------+
| id | select_type | table   | type | possible_keys | key  | Extra          |
+----+-------------+---------+------+---------------+------+----------------+
|  1 | SIMPLE      | tb_user | ALL  | NULL          | NULL | Using filesort | -- Using filesort
+----+-------------+---------+------+---------------+------+----------------+ -- 效率比较低

-- 按照age、phone升序排序，查看id、age、phone字段。
-- 没有索引包含这两个字段，所以不会使用索引进行排序，所以使用filesort排序方式，排序性能较低。
explain select id, age, phone from tb_user order by age, phone;
+----+-------------+---------+------+---------------+------+----------------+
| id | select_type | table   | type | possible_keys | key  | Extra          |
+----+-------------+---------+------+---------------+------+----------------+
|  1 | SIMPLE      | tb_user | ALL  | NULL          | NULL | Using filesort | -- Using filesort
+----+-------------+---------+------+---------------+------+----------------+ -- 效率比较低

-- 为这两个字段创建索引，然后排序看看使用哪种方式
create index idx_user_age_phone_aa on tb_user(age, phone);
-- 查看该SQL语句详细信息，通过有序索引顺序扫描直接返回有序数据
explain select id, age, phone from tb_user order by age, phone;
+----+-------------+---------+-------+---------------+-----------------------+-------------+
| id | select_type | table   | type  | possible_keys | key                   | Extra       |
+----+-------------+---------+-------+---------------+-----------------------+-------------+
|  1 | SIMPLE      | tb_user | index | NULL          | idx_user_age_phone_aa | Using index |
+----+-------------+---------+-------+---------------+-----------------------+-------------+

-- 一个字段升序，一个字段降序。此时会出现Backward index scan，它代表反向扫描索引。
-- 在MySQL中我们创建的索引，默认索引的叶子节点是从小到大排序的，我们反向查询的时候就会进行反向扫描
explain select id, age, phone from tb_user order by age desc, phone desc;
+----+-------------+-------+---------------+---------------------+--------------------------------+
| id | select_type | type  | possible_keys |key                  |Extra                           |
+----+-------------+-------+---------------+---------------------+--------------------------------+
|  1 | SIMPLE      | index | NULL          |idx_user_age_phone_aa|Backward index scan; Using index|
+----+-------------+-------+---------------+---------------------+--------------------------------+
```

**多字段排序时，也遵循最左前缀法则**

```sql
-- 根据phone，age进行升序排序。首先会根据phone字段排序，phone字段相同再根据age字段排序。
-- 多字段排序的时候也需要满足最左前缀法则，否则也会出现filesort
explain select id, age, phone from tb_user order by phone, age;
+----+-------------+-------+---------------+-----------------------+-----------------------------+
| id | select_type | type  | possible_keys | key                   | Extra                       |
+----+-------------+-------+---------------+-----------------------+-----------------------------+
|  1 | SIMPLE      | index | NULL          | idx_user_age_phone_aa | Using index; Using filesort |
+----+-------------+-------+---------------+-----------------------+-----------------------------+
```

**多字段升序和降序，要注意索引创建时的规则**

```sql
-- 根据age升序排序，phone降序排序。首先会根据age字段排序，phone字段相同再根据age字段排序。
explain select id, age, phone from tb_user order by age asc, phone desc ;
-- 创建索引时，如果未指定顺序，默认都是按照升序排序。查询时，一个升序，一个降序，此时就会出现Using filesort。
-- 可以创建索引的时候就弄成倒序的 create index idx_user_age_phone_ad on tb_user(age asc, phone desc);
+----+-------------+-------+---------------+-----------------------+-----------------------------+
| id | select_type | type  | possible_keys | key                   | Extra                       |
+----+-------------+-------+---------------+-----------------------+-----------------------------+
|  1 | SIMPLE      | index | NULL          | idx_user_age_phone_aa | Using index; Using filesort |
+----+-------------+-------+---------------+-----------------------+-----------------------------+
```

## 2.5 group by分组优化

在分组操作中，我们需要通过以下两点进行优化，以提升性能：

1. 在分组操作时，可以通过索引来提高效率。 
2. 分组操作时，索引的使用也是满足最左前缀法则的。

分组操作，我们主要来看看索引对于分组操作的影响。首先将tb_user表内索引除了主键索引外全部删除。

```sql
-- 删除索引
-- 删除idx_user_pro_age_sta索引
mysql> drop index idx_user_pro_age_sta on tb_user;
Query OK, 0 rows affected (0.04 sec)
Records: 0  Duplicates: 0  Warnings: 0

-- 删除idx_user_email_5索引
mysql> drop index idx_user_email_5 on tb_user;
Query OK, 0 rows affected (0.04 sec)
Records: 0  Duplicates: 0  Warnings: 0

-- 删除idx_user_age_phone_aa索引
mysql> drop index idx_user_age_phone_aa on tb_user;
Query OK, 0 rows affected (0.04 sec)
Records: 0  Duplicates: 0  Warnings: 0

-- 查询表中索引
mysql> show index from tb_user;
+---------+----------+--------------+-------------+------------+---------+------------+
| Table   | Key_name | Seq_in_index | Column_name | Index_type | Visible | Expression |
+---------+----------+--------------+-------------+------------+---------+------------+
| tb_user | PRIMARY  |            1 | id          | BTREE      | YES     | NULL       |
+---------+----------+--------------+-------------+------------+---------+------------+
```

接下来，在没有索引的情况下，执行如下SQL，查询执行计划：

```sql
-- 通过profession分组，然后查询分组之后的profession和数量
explain select profession, count(*) from tb_user group by profession;
+----+------+-----------------+
| id | type | Extra           | -- type: ALL 性能较差
+----+------+-----------------+ -- Extra: Using temporary 使用到了中间表
|  1 | ALL  | Using temporary |
+----+------+-----------------+
```

再针对于 profession， age，status 创建一个联合索引，再执行刚刚的SQL：

```sql
-- 创建索引
create index idx_user_pro_age_sta on tb_user(profession, age, status);
-- 查看执行情况
explain select profession, count(*) from tb_user group by profession;  
+----+-------+-------------+
| id | type  | Extra       | -- type: index性能比刚刚提升了  
+----+-------+-------------+ -- Extra: Using index  使用到了索引
|  1 | index | Using index |
+----+-------+-------------+

-- 根据age分组，这时候就会出现Using temporary。这是因为对于分组操作，在联合索引中，也是符合最左前缀法则的。
mysql> explain select age, count(*) from tb_user group by age;
+----+-------+----------------------+----------------------+------------------------------+
| id | type  | possible_keys        | key                  | Extra                        |
+----+-------+----------------------+----------------------+------------------------------+
|  1 | index | idx_user_pro_age_sta | idx_user_pro_age_sta | Using index; Using temporary |
+----+-------+----------------------+----------------------+------------------------------+
1 row in set, 1 warning (0.00 sec)
```

## 2.6 limit分页优化

```sql
-- 分页查询基本语法
select 字段列表 from 表名 limit 开始的索引，每页查询的条数;
select * from person limit 0, 3;		-- 第1页
select * from person limit 3, 3;		-- 第2页
select * from person limit 6, 3;		-- 第3页
```

在数据量比较大时，如果进行limit分页查询，越往后，分页查询效率越低。因为当在进行分页查询时，如果执行 `limit 2000000, 10` ，此时需要MySQL排序前2000010记录，仅仅返回 2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大 。

一般分页查询时，通过创建覆盖索引能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化。

```sql
-- select id from tb_sku order by id limit 2000000, 10 只查询出来主键，然后根据主键查询
explain select * from tb_sku t, (select id from tb_sku order by id limit 2000000,10) a where t.id = a.id;
```

## 2.7 count计数优化

`count()` 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是NULL，累计值就加 1，否则不加，最后返回累计值。 

InnoDB中调用`count(*)`会把数据逐行从引擎里面读出来，然后累积计数。而MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 `count(*)` 的时候会直接返回这个数，效率很高； 但如果是带条件的count，MyISAM也慢。 

InnoDB中的用法：`count(字段)`、`count(主键)`、`count(数字)`、`count(*)`。

- `count(字段)`：分为两种情况，有NOT NULL约束和没有NOT NULL约束。
  有NOT NULL约束：遍历整张表，把每一行的字段值都取出来，返回给服务层，直接按行进行累加。
  没有NOT NULL约束：InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为null，不为null，计数累加。 
- `count(主键)`：InnoDB 引擎会遍历整张表，把每一行的主键id值都取出来，返回给服务层。服务层拿到主键后，直接按行进行累加。主键不可能为NULL，所以不用判断是否为NULL。
  `count(主键)`比`count(字段)`快，因为不用判断是否为NULL。
- `count(数字)`：遍历整张表但不取值。服务层对于返回的每一行，放一个数字“1” 进去，直接按行进行累加。`count(数字)`比`count(主键 id)`快，因为`count(主键 id)`从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。
- `count(*)`：InnoDB引擎并不会把全部字段取出来，而是专门做了优化不取值，服务层直接按行进行累加。

按照效率排序的话，`count(字段)` < `count(主键 id)` < `count(1)` ≈ `count(*)`，所以尽量使用 `count(*)`。

